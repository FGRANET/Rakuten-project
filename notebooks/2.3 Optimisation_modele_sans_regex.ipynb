{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "828e03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation du texte sous forme de liste en string\n",
    "def jonction(liste):\n",
    "  result = \"\"\n",
    "  for token in liste:\n",
    "    result = result + token + \" \"\n",
    "  return result\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load,dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def optimisation_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,grid_search_cv):\n",
    "    #import du df\n",
    "    df = load(df_post_traduction)\n",
    "    #transformation de la future colonne feature en chaine de caractère\n",
    "    df[colonne_a_vectoriser]=df[colonne_a_vectoriser].apply(jonction)\n",
    "    #séparation des features et de la cible\n",
    "    data = df[colonne_a_vectoriser]\n",
    "    target = df[\"prdtypecode\"]\n",
    "    #séparation de train et test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42, stratify = target)\n",
    "    #vectorisation selon un nombre max de mots les plus fréquents\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    X_train = vectorizer.fit_transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "    scaler = StandardScaler().fit(np.asarray(X_train))\n",
    "    X_train = scaler.transform(np.asarray(X_train))\n",
    "    X_test = scaler.transform(np.asarray(X_test))\n",
    "    sel = SelectKBest(k=k_best)\n",
    "    sel.fit(np.asarray(X_train),y_train)\n",
    "    X_train = sel.transform(np.asarray(X_train))\n",
    "    X_test = sel.transform(np.asarray(X_test))\n",
    "    if os.path.exists(joblib_path_suivi_metrique):\n",
    "        df_import = load(joblib_path_suivi_metrique)\n",
    "        print(\"récupération du df existant\")\n",
    "    else:\n",
    "        df_import = pd.DataFrame(columns=[\"Max_features\",\"K_best\",\"Grid\",\"Hyperparamètres\",\"Best_param\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec\"])\n",
    "        print(\"création d'un dataframe\")\n",
    "    score = []\n",
    "    print(\"debut du grid:\",grid_search_cv)\n",
    "    debut = time.time()\n",
    "    grid_search_cv.fit(np.asarray(X_train),y_train)\n",
    "    print(\"fin du grid:\",grid_search_cv)\n",
    "    print(\"debut meilleur param:\",grid_search_cv.best_params_)\n",
    "    best_params = grid_search_cv.best_params_\n",
    "    best_rf_model = RandomForestClassifier(**best_params)\n",
    "    best_rf_model.fit(np.asarray(X_train), y_train)\n",
    "    y_pred  = best_rf_model.predict(np.asarray(X_test))\n",
    "    print(\"fin meilleur param\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    fin = time.time()\n",
    "    duree = fin - debut\n",
    "    model_scores = { \n",
    "            \"Max_features\": f\"{max_features}\",\n",
    "            \"K_best\":f\"{k_best}\",\n",
    "            \"Grid\": f\"{grid_search_cv}\",\n",
    "            \"Hyperparamètres\":f\"{param_grid}\",\n",
    "            \"Best_param\":f\"{best_params}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_weighted\": f1_weighted,\n",
    "            \"F1_macro\": f1_macro,\n",
    "            \"Duree en sec\": duree}\n",
    "    score.append(model_scores)\n",
    "    df_score = pd.DataFrame(score)\n",
    "    df = pd.concat([df_import, df_score], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "397376b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400],  # Nombre d'arbres dans la forêt\n",
    "    'criterion': ['gini'],  # Métrique de qualité de la division\n",
    "    'max_depth': [None],  # Profondeur maximale de chaque arbre\n",
    "    'min_samples_split': [5],  # Nombre minimal d'échantillons requis pour diviser un nœud\n",
    "    'min_samples_leaf': [1],  # Nombre minimal d'échantillons requis pour être une feuille\n",
    "    'max_features': ['log2'],  # Nombre maximal de fonctionnalités à considérer pour la division\n",
    "    'bootstrap': [False],  # Si l'échantillonnage bootstrap doit être utilisé\n",
    "    'class_weight': ['balanced'],  # Poids des classes pour la correction de déséquilibre\n",
    "    'random_state': [23],  # Seed pour la reproductibilité\n",
    "    'n_jobs': [-1]  # Utilisation de tous les cœurs de CPU}\n",
    "}\n",
    "\n",
    "gcv = GridSearchCV(estimator=rdf, param_grid = param_grid,cv=5, n_jobs=-1, scoring=\"f1_weighted\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Nombre d'arbres \n",
    "    'criterion': ['gini', 'entropy',],  # Métrique de qualité de la division\n",
    "    'max_depth': [None, 10, 20, 30],  # Profondeur maximale de chaque arbre\n",
    "    'min_samples_split': [2, 5, 10],  # Nombre minimal d'échantillons requis pour diviser un nœud\n",
    "    'min_samples_leaf': [1, 2, 4],  # Nombre minimal d'échantillons requis pour être une feuille\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Nombre maximal de fonctionnalités à considérer pour la division\n",
    "    'bootstrap': [True, False],  # Si l'échantillonnage bootstrap doit être utilisé\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],  # Poids des classes pour la correction de déséquilibre\n",
    "    'random_state': [23],  # Seed pour la reproductibilité\n",
    "    'n_jobs': [-1]  # Utilisation de tous les cœurs de CPU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5dc56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "récupération du df existant\n",
      "debut du grid: GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=23),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'bootstrap': [False], 'class_weight': ['balanced'],\n",
      "                         'criterion': ['gini'], 'max_depth': [None],\n",
      "                         'max_features': ['log2'], 'min_samples_leaf': [1],\n",
      "                         'min_samples_split': [5], 'n_estimators': [400],\n",
      "                         'n_jobs': [-1], 'random_state': [23]},\n",
      "             scoring='f1_weighted')\n",
      "fin du grid: GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=-1, random_state=23),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'bootstrap': [False], 'class_weight': ['balanced'],\n",
      "                         'criterion': ['gini'], 'max_depth': [None],\n",
      "                         'max_features': ['log2'], 'min_samples_leaf': [1],\n",
      "                         'min_samples_split': [5], 'n_estimators': [400],\n",
      "                         'n_jobs': [-1], 'random_state': [23]},\n",
      "             scoring='f1_weighted')\n",
      "debut meilleur param: {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400, 'n_jobs': -1, 'random_state': 23}\n",
      "fin meilleur param\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\franc\\\\AutoML\\\\df_optimisation.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_post_traduction = r\"C:\\Users\\franc\\AutoML\\df_train_post_trad.joblib\"\n",
    "colonne_a_vectoriser = \"mots_stem_sans_chiffres\"\n",
    "max_features = 4000\n",
    "k_best = 3000\n",
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_optimisation.joblib\"\n",
    "grid_search_cv = gcv\n",
    "df_optimisation = optimisation_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,grid_search_cv)\n",
    "dump(df_optimisation,r\"C:\\Users\\franc\\AutoML\\df_optimisation.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e99cd6e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_features</th>\n",
       "      <th>K_best</th>\n",
       "      <th>Grid</th>\n",
       "      <th>Hyperparamètres</th>\n",
       "      <th>Best_param</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.772136</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>1072.721818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.772688</td>\n",
       "      <td>0.773371</td>\n",
       "      <td>0.750832</td>\n",
       "      <td>1872.766705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.772136</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>1176.132017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.779381</td>\n",
       "      <td>0.780637</td>\n",
       "      <td>0.757437</td>\n",
       "      <td>1647.827343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.779381</td>\n",
       "      <td>0.780637</td>\n",
       "      <td>0.757437</td>\n",
       "      <td>1703.849127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.782758</td>\n",
       "      <td>0.782434</td>\n",
       "      <td>0.764278</td>\n",
       "      <td>773.802725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': ['balanced'], 'random_state':...</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.782881</td>\n",
       "      <td>0.782675</td>\n",
       "      <td>0.764457</td>\n",
       "      <td>714.752244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'class_weight': [None, 'balanced', 'balanced_...</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.782881</td>\n",
       "      <td>0.782675</td>\n",
       "      <td>0.764457</td>\n",
       "      <td>1777.478430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'n_estimators': [100, 200, 300], 'criterion':...</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 300}</td>\n",
       "      <td>0.772013</td>\n",
       "      <td>0.771371</td>\n",
       "      <td>0.750619</td>\n",
       "      <td>5582.291008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'n_estimators': [50, 100, 200, 300], 'criteri...</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.775636</td>\n",
       "      <td>0.775725</td>\n",
       "      <td>0.757550</td>\n",
       "      <td>2151.491883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'n_estimators': [300], 'criterion': ['gini', ...</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.785153</td>\n",
       "      <td>0.785194</td>\n",
       "      <td>0.767620</td>\n",
       "      <td>2974.031980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GridSearchCV(cv=5, estimator=RandomForestClass...</td>\n",
       "      <td>{'n_estimators': [400], 'criterion': ['gini'],...</td>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced...</td>\n",
       "      <td>0.786074</td>\n",
       "      <td>0.786339</td>\n",
       "      <td>0.768210</td>\n",
       "      <td>1621.449365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Max_features K_best                                               Grid  \\\n",
       "0          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "1          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "2          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "3          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "4          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "5          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "6          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "7          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "8          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "9          4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "10         4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "11         4000   3000  GridSearchCV(cv=5, estimator=RandomForestClass...   \n",
       "\n",
       "                                      Hyperparamètres  \\\n",
       "0   {'class_weight': ['balanced'], 'random_state':...   \n",
       "1   {'class_weight': ['balanced'], 'random_state':...   \n",
       "2   {'class_weight': ['balanced'], 'random_state':...   \n",
       "3   {'class_weight': ['balanced'], 'random_state':...   \n",
       "4   {'class_weight': ['balanced'], 'random_state':...   \n",
       "5   {'class_weight': ['balanced'], 'random_state':...   \n",
       "6   {'class_weight': ['balanced'], 'random_state':...   \n",
       "7   {'class_weight': [None, 'balanced', 'balanced_...   \n",
       "8   {'n_estimators': [100, 200, 300], 'criterion':...   \n",
       "9   {'n_estimators': [50, 100, 200, 300], 'criteri...   \n",
       "10  {'n_estimators': [300], 'criterion': ['gini', ...   \n",
       "11  {'n_estimators': [400], 'criterion': ['gini'],...   \n",
       "\n",
       "                                           Best_param  Accuracy  F1_weighted  \\\n",
       "0   {'class_weight': 'balanced', 'criterion': 'gin...  0.772136     0.772812   \n",
       "1   {'class_weight': 'balanced', 'criterion': 'gin...  0.772688     0.773371   \n",
       "2   {'class_weight': 'balanced', 'criterion': 'gin...  0.772136     0.772812   \n",
       "3   {'class_weight': 'balanced', 'criterion': 'gin...  0.779381     0.780637   \n",
       "4   {'class_weight': 'balanced', 'criterion': 'gin...  0.779381     0.780637   \n",
       "5   {'class_weight': 'balanced', 'criterion': 'gin...  0.782758     0.782434   \n",
       "6   {'bootstrap': False, 'class_weight': 'balanced...  0.782881     0.782675   \n",
       "7   {'bootstrap': False, 'class_weight': 'balanced...  0.782881     0.782675   \n",
       "8          {'criterion': 'gini', 'n_estimators': 300}  0.772013     0.771371   \n",
       "9   {'bootstrap': False, 'class_weight': 'balanced...  0.775636     0.775725   \n",
       "10  {'bootstrap': False, 'class_weight': 'balanced...  0.785153     0.785194   \n",
       "11  {'bootstrap': False, 'class_weight': 'balanced...  0.786074     0.786339   \n",
       "\n",
       "    F1_macro  Duree en sec  \n",
       "0   0.750719   1072.721818  \n",
       "1   0.750832   1872.766705  \n",
       "2   0.750719   1176.132017  \n",
       "3   0.757437   1647.827343  \n",
       "4   0.757437   1703.849127  \n",
       "5   0.764278    773.802725  \n",
       "6   0.764457    714.752244  \n",
       "7   0.764457   1777.478430  \n",
       "8   0.750619   5582.291008  \n",
       "9   0.757550   2151.491883  \n",
       "10  0.767620   2974.031980  \n",
       "11  0.768210   1621.449365  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_optimisation.joblib\"\n",
    "df_optimisation = load(joblib_path_suivi_metrique)\n",
    "df_optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f752fa",
   "metadata": {},
   "source": [
    "## Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "097ad4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'penalty': [\"l2\",None], \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    "    'solver': [\"lbfgs\"],\n",
    "    'max_iter': [100],\n",
    "    'class_weight':['balanced'],\n",
    "    'random_state': [23]}\n",
    "gcv = GridSearchCV(estimator=lr, param_grid = param_grid,cv=5, n_jobs=-1, scoring=\"f1_weighted\")  \n",
    "\"\"\"{'C': 0.01, 'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2', 'random_state': 23, 'solver': 'lbfgs'}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"param_grid = {\n",
    "    'penalty': ['l1', 'l2'], # Type de régularisation : l1 (Lasso) ou l2 (Ridge)\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # Inverse de la force de régularisation (plus C est grand, moins la régularisation est forte)\n",
    "    'solver': ['liblinear', 'saga'], # Algorithme d'optimisation (liblinear pour les petites données, saga pour les grandes données)\n",
    "    'max_iter': [100, 200, 300] # Nombre maximal d'itérations pour la convergence de l'optimisation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7212c7d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "récupération du df existant\n",
      "debut du grid: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
      "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'class_weight': ['balanced'], 'max_iter': [100],\n",
      "                         'penalty': ['l2', None], 'random_state': [23],\n",
      "                         'solver': ['lbfgs']},\n",
      "             scoring='f1_weighted')\n",
      "fin du grid: GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
      "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
      "                         'class_weight': ['balanced'], 'max_iter': [100],\n",
      "                         'penalty': ['l2', None], 'random_state': [23],\n",
      "                         'solver': ['lbfgs']},\n",
      "             scoring='f1_weighted')\n",
      "debut meilleur param: {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 100, 'penalty': 'l2', 'random_state': 23, 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m joblib_path_suivi_metrique \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfranc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAutoML\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdf_optimisation.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m grid_search_cv \u001b[38;5;241m=\u001b[39m gcv\n\u001b[1;32m----> 7\u001b[0m df_optimisation \u001b[38;5;241m=\u001b[39m \u001b[43moptimisation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_post_traduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolonne_a_vectoriser\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43mjoblib_path_suivi_metrique\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid_search_cv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m dump(df_optimisation,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfranc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAutoML\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdf_optimisation.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 54\u001b[0m, in \u001b[0;36moptimisation_model\u001b[1;34m(df_post_traduction, colonne_a_vectoriser, max_features, k_best, joblib_path_suivi_metrique, grid_search_cv)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebut meilleur param:\u001b[39m\u001b[38;5;124m\"\u001b[39m,grid_search_cv\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     53\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search_cv\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m---> 54\u001b[0m best_rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params)\n\u001b[0;32m     55\u001b[0m best_rf_model\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39masarray(X_train), y_train)\n\u001b[0;32m     56\u001b[0m y_pred  \u001b[38;5;241m=\u001b[39m best_rf_model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39masarray(X_test))\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'C'"
     ]
    }
   ],
   "source": [
    "df_post_traduction = r\"C:\\Users\\franc\\AutoML\\df_train_post_trad.joblib\"\n",
    "colonne_a_vectoriser = \"mots_stem_sans_chiffres\"\n",
    "max_features = 4000\n",
    "k_best = 3000\n",
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_optimisation.joblib\"\n",
    "grid_search_cv = gcv\n",
    "df_optimisation = optimisation_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,grid_search_cv)\n",
    "dump(df_optimisation,r\"C:\\Users\\franc\\AutoML\\df_optimisation.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdf4b9",
   "metadata": {},
   "source": [
    "### Sans grid search pour tester quelques combinaison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5392a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation du texte sous forme de liste en string\n",
    "def jonction(liste):\n",
    "  result = \"\"\n",
    "  for token in liste:\n",
    "    result = result + token + \" \"\n",
    "  return result\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load,dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,liste_modele):\n",
    "    #import du df\n",
    "    df = load(df_post_traduction)\n",
    "    #transformation de la future colonne feature en chaine de caractère\n",
    "    df[colonne_a_vectoriser]=df[colonne_a_vectoriser].apply(jonction)\n",
    "    #séparation des features et de la cible\n",
    "    data = df[colonne_a_vectoriser]\n",
    "    target = df[\"prdtypecode\"]\n",
    "    #séparation de train et test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42, stratify = target)\n",
    "    #vectorisation selon un nombre max de mots les plus fréquents\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    X_train = vectorizer.fit_transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "    scaler = StandardScaler().fit(np.asarray(X_train))\n",
    "    X_train = scaler.transform(np.asarray(X_train))\n",
    "    X_test = scaler.transform(np.asarray(X_test))\n",
    "    sel = SelectKBest(k=k_best)\n",
    "    sel.fit(np.asarray(X_train),y_train)\n",
    "    X_train = sel.transform(np.asarray(X_train))\n",
    "    X_test = sel.transform(np.asarray(X_test))\n",
    "    if os.path.exists(joblib_path_suivi_metrique):\n",
    "        df_import = load(joblib_path_suivi_metrique)\n",
    "        print(\"récupération du df existant\")\n",
    "    else:\n",
    "        df_import = pd.DataFrame(columns=[\"Colonne vectorisée\",\"Max_features\",\"K_best\",\"Model\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec\"])\n",
    "        print(\"création d'un dataframe\")\n",
    "    score = []\n",
    "    for model in liste_modele:\n",
    "        print(\"debut du modèle:\",model)\n",
    "        debut = time.time()\n",
    "        model.fit(np.asarray(X_train),y_train)\n",
    "        y_pred = model.predict(np.asarray(X_test))\n",
    "        print(\"fin du modèle:\",model)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        fin = time.time()\n",
    "        duree = fin - debut\n",
    "        model_scores = {\n",
    "            \"Colonne vectorisée\":f\"{colonne_a_vectoriser}\",\n",
    "            \"Max_features\": f\"{max_features}\",\n",
    "            \"K_best\":f\"{k_best}\",\n",
    "            \"Model\": f\"{model}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_weighted\": f1_weighted,\n",
    "            \"F1_macro\": f1_macro,\n",
    "            \"Duree en sec\": duree}\n",
    "        score.append(model_scores)\n",
    "    df_score = pd.DataFrame(score)\n",
    "    df = pd.concat([df_import, df_score], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83ffc82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "récupération du df existant\n",
      "debut du modèle: LogisticRegression(C=0.01, class_weight='balanced', max_iter=500,\n",
      "                   multi_class='multinomial', random_state=23, solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin du modèle: LogisticRegression(C=0.01, class_weight='balanced', max_iter=500,\n",
      "                   multi_class='multinomial', random_state=23, solver='saga')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\franc\\\\AutoML\\\\df_score.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_post_traduction = r\"C:\\Users\\franc\\AutoML\\df_train_post_trad.joblib\"\n",
    "max_features = 4000\n",
    "k_best = 3000\n",
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_score.joblib\"\n",
    "colonne_a_vectoriser = \"mots_stem_sans_chiffres\"\n",
    "lr3 = LogisticRegression(multi_class=\"multinomial\",C= 0.01, class_weight= 'balanced', max_iter= 500, penalty= 'l2', random_state= 23, solver= 'saga')\n",
    "liste_modele = [lr3]\n",
    "df_score = test_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,liste_modele)\n",
    "dump(df_score,r\"C:\\Users\\franc\\AutoML\\df_score.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda175a",
   "metadata": {},
   "source": [
    "### BalancedRandomForestClassifier avec les paramètres du meilleure RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99fa41c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "récupération du df existant\n",
      "debut du modèle: BalancedRandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                               max_features='log2', min_samples_split=5,\n",
      "                               n_estimators=1000, n_jobs=-1, random_state=23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:546: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\franc\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:558: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin du modèle: BalancedRandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                               max_features='log2', min_samples_split=5,\n",
      "                               n_estimators=1000, n_jobs=-1, random_state=23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\franc\\\\AutoML\\\\df_score.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "df_post_traduction = r\"C:\\Users\\franc\\AutoML\\df_train_post_trad.joblib\"\n",
    "max_features = 4000\n",
    "k_best = 3000\n",
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_score.joblib\"\n",
    "colonne_a_vectoriser = \"mots_stem_sans_chiffres\"\n",
    "brfc = BalancedRandomForestClassifier(n_estimators=1000,  criterion='gini',  max_depth= None,  \n",
    "                               min_samples_split= 5, min_samples_leaf = 1, max_features='log2',  \n",
    "                               bootstrap=False,  class_weight='balanced',  random_state=23,  n_jobs=-1)\n",
    "liste_modele = [brfc]\n",
    "df_score = test_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,liste_modele)\n",
    "dump(df_score,r\"C:\\Users\\franc\\AutoML\\df_score.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a404d1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colonne vectorisée</th>\n",
       "      <th>Max_features</th>\n",
       "      <th>K_best</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.737689</td>\n",
       "      <td>0.742634</td>\n",
       "      <td>0.713987</td>\n",
       "      <td>33.572307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.573560</td>\n",
       "      <td>0.580204</td>\n",
       "      <td>0.539838</td>\n",
       "      <td>46.121506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.699067</td>\n",
       "      <td>0.702138</td>\n",
       "      <td>0.673113</td>\n",
       "      <td>86.763731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.772136</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>80.730617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.709382</td>\n",
       "      <td>0.718596</td>\n",
       "      <td>0.679694</td>\n",
       "      <td>150.788608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mots_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.737996</td>\n",
       "      <td>0.742530</td>\n",
       "      <td>0.712957</td>\n",
       "      <td>34.400597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mots_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.573612</td>\n",
       "      <td>0.534399</td>\n",
       "      <td>46.437106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mots_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.699435</td>\n",
       "      <td>0.702849</td>\n",
       "      <td>0.672202</td>\n",
       "      <td>84.432850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mots_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.770109</td>\n",
       "      <td>0.771216</td>\n",
       "      <td>0.748568</td>\n",
       "      <td>80.628054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mots_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.708523</td>\n",
       "      <td>0.716657</td>\n",
       "      <td>0.682357</td>\n",
       "      <td>143.169274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mots_lem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.738671</td>\n",
       "      <td>0.743250</td>\n",
       "      <td>0.712571</td>\n",
       "      <td>34.421438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mots_lem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.570920</td>\n",
       "      <td>0.582403</td>\n",
       "      <td>0.545858</td>\n",
       "      <td>46.607042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mots_lem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.697839</td>\n",
       "      <td>0.701991</td>\n",
       "      <td>0.674470</td>\n",
       "      <td>82.725072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mots_lem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.763662</td>\n",
       "      <td>0.764670</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>79.471742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mots_lem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.708707</td>\n",
       "      <td>0.716832</td>\n",
       "      <td>0.682613</td>\n",
       "      <td>146.663627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mots_lem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.737566</td>\n",
       "      <td>0.742141</td>\n",
       "      <td>0.712095</td>\n",
       "      <td>34.721371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mots_lem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.576814</td>\n",
       "      <td>0.582204</td>\n",
       "      <td>0.544146</td>\n",
       "      <td>46.168040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mots_lem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.695690</td>\n",
       "      <td>0.699613</td>\n",
       "      <td>0.671076</td>\n",
       "      <td>88.799386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mots_lem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.765688</td>\n",
       "      <td>0.767049</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>84.846292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mots_lem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.708031</td>\n",
       "      <td>0.717013</td>\n",
       "      <td>0.682106</td>\n",
       "      <td>151.611055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mots_lem_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.738978</td>\n",
       "      <td>0.743443</td>\n",
       "      <td>0.714952</td>\n",
       "      <td>34.285940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mots_lem_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.565885</td>\n",
       "      <td>0.577421</td>\n",
       "      <td>0.538678</td>\n",
       "      <td>46.545545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mots_lem_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.696979</td>\n",
       "      <td>0.699962</td>\n",
       "      <td>0.673545</td>\n",
       "      <td>84.972584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mots_lem_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.767408</td>\n",
       "      <td>0.768059</td>\n",
       "      <td>0.747478</td>\n",
       "      <td>80.083964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mots_lem_stem</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.710672</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.687430</td>\n",
       "      <td>139.129442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mots_lem_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.739776</td>\n",
       "      <td>0.744157</td>\n",
       "      <td>0.717056</td>\n",
       "      <td>34.623655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mots_lem_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.574481</td>\n",
       "      <td>0.581349</td>\n",
       "      <td>0.542256</td>\n",
       "      <td>46.750477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mots_lem_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.697225</td>\n",
       "      <td>0.699923</td>\n",
       "      <td>0.670037</td>\n",
       "      <td>92.671640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mots_lem_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.766609</td>\n",
       "      <td>0.766711</td>\n",
       "      <td>0.746073</td>\n",
       "      <td>80.706727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mots_lem_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.710365</td>\n",
       "      <td>0.718762</td>\n",
       "      <td>0.683327</td>\n",
       "      <td>140.737188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>SVC(C=0.1, random_state=23)</td>\n",
       "      <td>0.511544</td>\n",
       "      <td>0.508010</td>\n",
       "      <td>0.425062</td>\n",
       "      <td>8648.517462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.743276</td>\n",
       "      <td>0.758248</td>\n",
       "      <td>0.733305</td>\n",
       "      <td>3852.324328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(random_state=23)</td>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.746604</td>\n",
       "      <td>0.726534</td>\n",
       "      <td>31.477872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.708297</td>\n",
       "      <td>0.679179</td>\n",
       "      <td>64.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state...</td>\n",
       "      <td>0.768758</td>\n",
       "      <td>0.767993</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>74.080256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(random_state=23)</td>\n",
       "      <td>0.737075</td>\n",
       "      <td>0.741370</td>\n",
       "      <td>0.712791</td>\n",
       "      <td>90.523888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balan...</td>\n",
       "      <td>0.748803</td>\n",
       "      <td>0.758567</td>\n",
       "      <td>0.729158</td>\n",
       "      <td>35.301943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balan...</td>\n",
       "      <td>0.749232</td>\n",
       "      <td>0.758711</td>\n",
       "      <td>0.729952</td>\n",
       "      <td>64.888665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balan...</td>\n",
       "      <td>0.749232</td>\n",
       "      <td>0.758711</td>\n",
       "      <td>0.729952</td>\n",
       "      <td>61.788401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balan...</td>\n",
       "      <td>0.749355</td>\n",
       "      <td>0.758883</td>\n",
       "      <td>0.730084</td>\n",
       "      <td>135.595617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight='balan...</td>\n",
       "      <td>0.746347</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.730853</td>\n",
       "      <td>6898.612571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mots_stem_sans_chiffres</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(bootstrap=False...</td>\n",
       "      <td>0.715093</td>\n",
       "      <td>0.727732</td>\n",
       "      <td>0.682037</td>\n",
       "      <td>471.475646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Colonne vectorisée Max_features K_best  \\\n",
       "0       mots_stem_sans_chiffres         4000   3000   \n",
       "1       mots_stem_sans_chiffres         4000   3000   \n",
       "2       mots_stem_sans_chiffres         4000   3000   \n",
       "3       mots_stem_sans_chiffres         4000   3000   \n",
       "4       mots_stem_sans_chiffres         4000   3000   \n",
       "5                     mots_stem         4000   3000   \n",
       "6                     mots_stem         4000   3000   \n",
       "7                     mots_stem         4000   3000   \n",
       "8                     mots_stem         4000   3000   \n",
       "9                     mots_stem         4000   3000   \n",
       "10                     mots_lem         4000   3000   \n",
       "11                     mots_lem         4000   3000   \n",
       "12                     mots_lem         4000   3000   \n",
       "13                     mots_lem         4000   3000   \n",
       "14                     mots_lem         4000   3000   \n",
       "15       mots_lem_sans_chiffres         4000   3000   \n",
       "16       mots_lem_sans_chiffres         4000   3000   \n",
       "17       mots_lem_sans_chiffres         4000   3000   \n",
       "18       mots_lem_sans_chiffres         4000   3000   \n",
       "19       mots_lem_sans_chiffres         4000   3000   \n",
       "20                mots_lem_stem         4000   3000   \n",
       "21                mots_lem_stem         4000   3000   \n",
       "22                mots_lem_stem         4000   3000   \n",
       "23                mots_lem_stem         4000   3000   \n",
       "24                mots_lem_stem         4000   3000   \n",
       "25  mots_lem_stem_sans_chiffres         4000   3000   \n",
       "26  mots_lem_stem_sans_chiffres         4000   3000   \n",
       "27  mots_lem_stem_sans_chiffres         4000   3000   \n",
       "28  mots_lem_stem_sans_chiffres         4000   3000   \n",
       "29  mots_lem_stem_sans_chiffres         4000   3000   \n",
       "30      mots_stem_sans_chiffres         4000   3000   \n",
       "31      mots_stem_sans_chiffres         4000   3000   \n",
       "32      mots_stem_sans_chiffres         4000   3000   \n",
       "33      mots_stem_sans_chiffres         4000   3000   \n",
       "34      mots_stem_sans_chiffres         4000   3000   \n",
       "35      mots_stem_sans_chiffres         4000   3000   \n",
       "36      mots_stem_sans_chiffres         4000   3000   \n",
       "37      mots_stem_sans_chiffres         4000   3000   \n",
       "38      mots_stem_sans_chiffres         4000   3000   \n",
       "39      mots_stem_sans_chiffres         4000   3000   \n",
       "40      mots_stem_sans_chiffres         4000   3000   \n",
       "41      mots_stem_sans_chiffres         4000   3000   \n",
       "\n",
       "                                                Model  Accuracy  F1_weighted  \\\n",
       "0   LogisticRegression(class_weight='balanced', ra...  0.737689     0.742634   \n",
       "1                     KNeighborsClassifier(n_jobs=-1)  0.573560     0.580204   \n",
       "2   DecisionTreeClassifier(class_weight='balanced'...  0.699067     0.702138   \n",
       "3   RandomForestClassifier(class_weight='balanced'...  0.772136     0.772812   \n",
       "4   BalancedRandomForestClassifier(class_weight='b...  0.709382     0.718596   \n",
       "5   LogisticRegression(class_weight='balanced', ra...  0.737996     0.742530   \n",
       "6                     KNeighborsClassifier(n_jobs=-1)  0.562937     0.573612   \n",
       "7   DecisionTreeClassifier(class_weight='balanced'...  0.699435     0.702849   \n",
       "8   RandomForestClassifier(class_weight='balanced'...  0.770109     0.771216   \n",
       "9   BalancedRandomForestClassifier(class_weight='b...  0.708523     0.716657   \n",
       "10  LogisticRegression(class_weight='balanced', ra...  0.738671     0.743250   \n",
       "11                    KNeighborsClassifier(n_jobs=-1)  0.570920     0.582403   \n",
       "12  DecisionTreeClassifier(class_weight='balanced'...  0.697839     0.701991   \n",
       "13  RandomForestClassifier(class_weight='balanced'...  0.763662     0.764670   \n",
       "14  BalancedRandomForestClassifier(class_weight='b...  0.708707     0.716832   \n",
       "15  LogisticRegression(class_weight='balanced', ra...  0.737566     0.742141   \n",
       "16                    KNeighborsClassifier(n_jobs=-1)  0.576814     0.582204   \n",
       "17  DecisionTreeClassifier(class_weight='balanced'...  0.695690     0.699613   \n",
       "18  RandomForestClassifier(class_weight='balanced'...  0.765688     0.767049   \n",
       "19  BalancedRandomForestClassifier(class_weight='b...  0.708031     0.717013   \n",
       "20  LogisticRegression(class_weight='balanced', ra...  0.738978     0.743443   \n",
       "21                    KNeighborsClassifier(n_jobs=-1)  0.565885     0.577421   \n",
       "22  DecisionTreeClassifier(class_weight='balanced'...  0.696979     0.699962   \n",
       "23  RandomForestClassifier(class_weight='balanced'...  0.767408     0.768059   \n",
       "24  BalancedRandomForestClassifier(class_weight='b...  0.710672     0.718593   \n",
       "25  LogisticRegression(class_weight='balanced', ra...  0.739776     0.744157   \n",
       "26                    KNeighborsClassifier(n_jobs=-1)  0.574481     0.581349   \n",
       "27  DecisionTreeClassifier(class_weight='balanced'...  0.697225     0.699923   \n",
       "28  RandomForestClassifier(class_weight='balanced'...  0.766609     0.766711   \n",
       "29  BalancedRandomForestClassifier(class_weight='b...  0.710365     0.718762   \n",
       "30                        SVC(C=0.1, random_state=23)  0.511544     0.508010   \n",
       "31        GradientBoostingClassifier(random_state=23)  0.743276     0.758248   \n",
       "32                LogisticRegression(random_state=23)  0.744013     0.746604   \n",
       "33            DecisionTreeClassifier(random_state=23)  0.706803     0.708297   \n",
       "34  RandomForestClassifier(n_jobs=-1, random_state...  0.768758     0.767993   \n",
       "35    BalancedRandomForestClassifier(random_state=23)  0.737075     0.741370   \n",
       "36  LogisticRegression(C=0.01, class_weight='balan...  0.748803     0.758567   \n",
       "37  LogisticRegression(C=0.01, class_weight='balan...  0.749232     0.758711   \n",
       "38  LogisticRegression(C=0.01, class_weight='balan...  0.749232     0.758711   \n",
       "39  LogisticRegression(C=0.01, class_weight='balan...  0.749355     0.758883   \n",
       "40  LogisticRegression(C=0.01, class_weight='balan...  0.746347     0.758025   \n",
       "41  BalancedRandomForestClassifier(bootstrap=False...  0.715093     0.727732   \n",
       "\n",
       "    F1_macro  Duree en sec  \n",
       "0   0.713987     33.572307  \n",
       "1   0.539838     46.121506  \n",
       "2   0.673113     86.763731  \n",
       "3   0.750719     80.730617  \n",
       "4   0.679694    150.788608  \n",
       "5   0.712957     34.400597  \n",
       "6   0.534399     46.437106  \n",
       "7   0.672202     84.432850  \n",
       "8   0.748568     80.628054  \n",
       "9   0.682357    143.169274  \n",
       "10  0.712571     34.421438  \n",
       "11  0.545858     46.607042  \n",
       "12  0.674470     82.725072  \n",
       "13  0.745042     79.471742  \n",
       "14  0.682613    146.663627  \n",
       "15  0.712095     34.721371  \n",
       "16  0.544146     46.168040  \n",
       "17  0.671076     88.799386  \n",
       "18  0.745566     84.846292  \n",
       "19  0.682106    151.611055  \n",
       "20  0.714952     34.285940  \n",
       "21  0.538678     46.545545  \n",
       "22  0.673545     84.972584  \n",
       "23  0.747478     80.083964  \n",
       "24  0.687430    139.129442  \n",
       "25  0.717056     34.623655  \n",
       "26  0.542256     46.750477  \n",
       "27  0.670037     92.671640  \n",
       "28  0.746073     80.706727  \n",
       "29  0.683327    140.737188  \n",
       "30  0.425062   8648.517462  \n",
       "31  0.733305   3852.324328  \n",
       "32  0.726534     31.477872  \n",
       "33  0.679179     64.001309  \n",
       "34  0.747480     74.080256  \n",
       "35  0.712791     90.523888  \n",
       "36  0.729158     35.301943  \n",
       "37  0.729952     64.888665  \n",
       "38  0.729952     61.788401  \n",
       "39  0.730084    135.595617  \n",
       "40  0.730853   6898.612571  \n",
       "41  0.682037    471.475646  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load(\"df_score.joblib\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
