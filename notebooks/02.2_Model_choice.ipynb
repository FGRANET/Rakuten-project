{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f32b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation du texte sous forme de liste en string\n",
    "def jonction(liste):\n",
    "  result = \"\"\n",
    "  for token in liste:\n",
    "    result = result + token + \" \"\n",
    "  return result\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load,dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,liste_modele):\n",
    "    #import du df\n",
    "    df = load(df_post_traduction)\n",
    "    #transformation de la future colonne feature en chaine de caractère\n",
    "    df[colonne_a_vectoriser]=df[colonne_a_vectoriser].apply(jonction)\n",
    "    #séparation des features et de la cible\n",
    "    data = df[colonne_a_vectoriser]\n",
    "    target = df[\"prdtypecode\"]\n",
    "    #séparation de train et test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42, stratify = target)\n",
    "    #vectorisation selon un nombre max de mots les plus fréquents\n",
    "    vectorizer = CountVectorizer(max_features=max_features)\n",
    "    X_train = vectorizer.fit_transform(X_train).todense()\n",
    "    X_test = vectorizer.transform(X_test).todense()\n",
    "    scaler = StandardScaler().fit(np.asarray(X_train))\n",
    "    X_train = scaler.transform(np.asarray(X_train))\n",
    "    X_test = scaler.transform(np.asarray(X_test))\n",
    "    sel = SelectKBest(k=k_best)\n",
    "    sel.fit(np.asarray(X_train),y_train)\n",
    "    X_train = sel.transform(np.asarray(X_train))\n",
    "    X_test = sel.transform(np.asarray(X_test))\n",
    "    if os.path.exists(joblib_path_suivi_metrique):\n",
    "        df_import = load(joblib_path_suivi_metrique)\n",
    "        print(\"récupération du df existant\")\n",
    "    else:\n",
    "        df_import = pd.DataFrame(columns=[\"Max_features\",\"K_best\",\"Model\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec\"])\n",
    "        print(\"création d'un dataframe\")\n",
    "    score = []\n",
    "    for model in liste_modele:\n",
    "        print(\"debut du modèle:\",model)\n",
    "        debut = time.time()\n",
    "        model.fit(np.asarray(X_train),y_train)\n",
    "        y_pred = model.predict(np.asarray(X_test))\n",
    "        print(\"fin du modèle:\",model)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        fin = time.time()\n",
    "        duree = fin - debut\n",
    "        model_scores = { \n",
    "            \"Max_features\": f\"{max_features}\",\n",
    "            \"K_best\":f\"{k_best}\",\n",
    "            \"Model\": f\"{model}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_weighted\": f1_weighted,\n",
    "            \"F1_macro\": f1_macro,\n",
    "            \"Duree en sec\": duree}\n",
    "        score.append(model_scores)\n",
    "    df_score = pd.DataFrame(score)\n",
    "    df = pd.concat([df_import, df_score], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562544ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "\"\"\"lr = LogisticRegression(random_state=23,class_weight=\"balanced\")\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "dt = DecisionTreeClassifier(random_state=23,class_weight=\"balanced\")\n",
    "svc = svm.SVC(random_state=23,class_weight=\"balanced\") #probleme \n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23,class_weight=\"balanced\")\n",
    "gbc = GradientBoostingClassifier(random_state = 23)\n",
    "brdf = BalancedRandomForestClassifier(random_state = 23,class_weight=\"balanced\")\"\"\"\n",
    "#lr = LogisticRegression(random_state=23,)\n",
    "#lr = LogisticRegression(random_state=23, max_iter=1000)\n",
    "lr = LogisticRegression(random_state=23, max_iter=1000,solver='saga')\n",
    "svc = svm.SVC(C=0.1,kernel = \"linear\", random_state=23)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "dt = DecisionTreeClassifier(random_state=23)\n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23)\n",
    "gbc = GradientBoostingClassifier(random_state = 23)\n",
    "brdf = BalancedRandomForestClassifier(random_state = 23) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc4c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "récupération du df existant\n",
      "debut du modèle: LogisticRegression(max_iter=1000, random_state=23, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "df_post_traduction = r\"C:\\Users\\franc\\AutoML\\df_train_post_trad.joblib\"\n",
    "colonne_a_vectoriser = \"mots_stem_sans_chiffres\"\n",
    "max_features = 4000\n",
    "k_best = 3000\n",
    "joblib_path_suivi_metrique = r\"C:\\Users\\franc\\AutoML\\df_score.joblib\"\n",
    "liste_modele = [lr,svc]\n",
    "df_score = test_model(df_post_traduction,colonne_a_vectoriser,max_features,k_best,joblib_path_suivi_metrique,liste_modele)\n",
    "dump(df_score,r\"C:\\Users\\franc\\AutoML\\df_score.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a9f19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_features</th>\n",
       "      <th>K_best</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>0.737689</td>\n",
       "      <td>0.742634</td>\n",
       "      <td>0.713987</td>\n",
       "      <td>33.074111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>KNeighborsClassifier(n_jobs=-1)</td>\n",
       "      <td>0.573560</td>\n",
       "      <td>0.580204</td>\n",
       "      <td>0.539838</td>\n",
       "      <td>45.720312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.699067</td>\n",
       "      <td>0.702138</td>\n",
       "      <td>0.673113</td>\n",
       "      <td>83.353033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.772136</td>\n",
       "      <td>0.772812</td>\n",
       "      <td>0.750719</td>\n",
       "      <td>77.130688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(class_weight='b...</td>\n",
       "      <td>0.709382</td>\n",
       "      <td>0.718596</td>\n",
       "      <td>0.679694</td>\n",
       "      <td>145.135950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(random_state=23)</td>\n",
       "      <td>0.744013</td>\n",
       "      <td>0.746604</td>\n",
       "      <td>0.726534</td>\n",
       "      <td>33.781977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.706803</td>\n",
       "      <td>0.708297</td>\n",
       "      <td>0.679179</td>\n",
       "      <td>80.784523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state...</td>\n",
       "      <td>0.768758</td>\n",
       "      <td>0.767993</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>78.348780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>BalancedRandomForestClassifier(random_state=23)</td>\n",
       "      <td>0.737075</td>\n",
       "      <td>0.741370</td>\n",
       "      <td>0.712791</td>\n",
       "      <td>136.097793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>0.729277</td>\n",
       "      <td>0.731983</td>\n",
       "      <td>0.706516</td>\n",
       "      <td>318.753879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Max_features K_best                                              Model  \\\n",
       "0         4000   3000  LogisticRegression(class_weight='balanced', ra...   \n",
       "1         4000   3000                    KNeighborsClassifier(n_jobs=-1)   \n",
       "2         4000   3000  DecisionTreeClassifier(class_weight='balanced'...   \n",
       "3         4000   3000  RandomForestClassifier(class_weight='balanced'...   \n",
       "4         4000   3000  BalancedRandomForestClassifier(class_weight='b...   \n",
       "5         4000   3000                LogisticRegression(random_state=23)   \n",
       "6         4000   3000            DecisionTreeClassifier(random_state=23)   \n",
       "7         4000   3000  RandomForestClassifier(n_jobs=-1, random_state...   \n",
       "8         4000   3000    BalancedRandomForestClassifier(random_state=23)   \n",
       "9         4000   3000  LogisticRegression(max_iter=1000, random_state...   \n",
       "\n",
       "   Accuracy  F1_weighted  F1_macro  Duree en sec  \n",
       "0  0.737689     0.742634  0.713987     33.074111  \n",
       "1  0.573560     0.580204  0.539838     45.720312  \n",
       "2  0.699067     0.702138  0.673113     83.353033  \n",
       "3  0.772136     0.772812  0.750719     77.130688  \n",
       "4  0.709382     0.718596  0.679694    145.135950  \n",
       "5  0.744013     0.746604  0.726534     33.781977  \n",
       "6  0.706803     0.708297  0.679179     80.784523  \n",
       "7  0.768758     0.767993  0.747480     78.348780  \n",
       "8  0.737075     0.741370  0.712791    136.097793  \n",
       "9  0.729277     0.731983  0.706516    318.753879  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= load(r\"C:\\Users\\franc\\AutoML\\df_score.joblib\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
