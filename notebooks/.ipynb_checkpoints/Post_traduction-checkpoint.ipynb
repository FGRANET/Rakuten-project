{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6BCJzFR_sxK",
    "outputId": "09110cff-44d5-4690-e45b-d8bcd73387bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Rakuten\n"
     ]
    }
   ],
   "source": [
    "\"\"\"#import du drive de google dans google collab\n",
    "from google.colab import drive\n",
    "#mise en place du drive à l'emplacement /content/drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#accés exclusif au dossier partagé Rakuten\n",
    "Rakuten_path = '/content/drive/MyDrive/Rakuten'\n",
    "%cd \"{Rakuten_path}\"  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duUabS8O4Glc",
    "outputId": "21a58234-a82c-4fb5-94d8-920c854ebd30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\franc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\franc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.6.0/fr_core_news_md-3.6.0-py3-none-any.whl (45.8 MB)\n",
      "     ---------------------------------------- 45.8/45.8 MB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from fr-core-news-md==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (63.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (1.26.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\franc\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\franc\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-md==3.6.0) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_md')\n",
      "Requirement already satisfied: Unidecode in c:\\users\\franc\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "#Import des packages\n",
    "import pandas as pd\n",
    "\n",
    "#Tokenisation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Sauvegarde\n",
    "from joblib import dump,load\n",
    "\n",
    "#import stem\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "porter_stemmer = FrenchStemmer()\n",
    "\n",
    "#import lemme\n",
    "#à lancer selon l'environnement\n",
    "\n",
    "!python -m spacy download fr_core_news_md\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "\n",
    "!pip install Unidecode\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EqJJHYpv2wSo"
   },
   "outputs": [],
   "source": [
    "from nltk.sem.logic import Tokens\n",
    "#fonction pour gestion de la ponctuation et des balises avant suppression\n",
    "def remplacement(text):\n",
    "  list_ponctuation = [\",\",\".\",\"?\",\"-\",\"!\",\"/\",\"\\\\\",\"'\",\":\",\"!\"]\n",
    "  #ajout d'un espace avant et après ponctuation pour éviter des erreurs de tokenisation\n",
    "  for i in list_ponctuation:\n",
    "    text = text.replace(i,\" \"+i+\" \")\n",
    "  #ajout d'espace avant ou après selon chevron pour éviter concatenation de mots après retrait balise html\n",
    "  text = text.replace(\"<\",\" <\")\n",
    "  text = text.replace(\">\",\"> \")\n",
    "  #gestion des caractères mal encodés hors html (A RETRAVAILLER EN UTILISANT PYENCHANT)\n",
    "  text = text.replace(\"à¢\",\"â\")\n",
    "  text = text.replace(\"â¿¿\",\"'\")\n",
    "  text = text.replace(\"Â°\",\"°\")\n",
    "  text = text.replace(\"¿\",\"oe\")\n",
    "  #suppression encodage html\n",
    "  from bs4 import BeautifulSoup\n",
    "  soup = BeautifulSoup(text, 'html.parser')\n",
    "  text = soup.get_text()\n",
    "  return text\n",
    "\n",
    "\"\"\"def encodage_html_liste(liste):\n",
    "  from bs4 import BeautifulSoup\n",
    "  nouvelle_liste=[]\n",
    "  for i in liste:\n",
    "    nouvelle_sous_liste=[]\n",
    "    for j in i:\n",
    "      soup = BeautifulSoup(j, 'html.parser')\n",
    "      nouvelle_sous_liste.append(soup.get_text() )\n",
    "    nouvelle_liste.append(nouvelle_sous_liste)\n",
    "  return nouvelle_liste\"\"\"\n",
    "\n",
    "def encodage_html_liste(liste):\n",
    "  from bs4 import BeautifulSoup\n",
    "  nouvelle_liste = []\n",
    "  for item in liste:\n",
    "    if isinstance(item, str):\n",
    "      soup = BeautifulSoup(item, 'html.parser')\n",
    "      nouvelle_liste.append(soup.get_text())\n",
    "    elif isinstance(item, list):\n",
    "      sublist = []\n",
    "      for sub_item in item:\n",
    "        if isinstance(sub_item, str):\n",
    "          soup = BeautifulSoup(sub_item, 'html.parser')\n",
    "          sublist.append(soup.get_text())\n",
    "        else:\n",
    "          sublist.append(sub_item)\n",
    "      nouvelle_liste.append(sublist)\n",
    "  return nouvelle_liste\n",
    "\n",
    "def tokenisation(texte):\n",
    "  doc = nlp(texte)\n",
    "  liste = [i.text for i in doc]\n",
    "  return liste\n",
    "\n",
    "#fonction de détection de langue avec API Google\n",
    "def detect_language(text):\n",
    "  result = client.detect_language(text)\n",
    "  return result\n",
    "\n",
    "#Fonction de traduction API Google\n",
    "def translate_list(liste):\n",
    "  resultat = []\n",
    "  for i in liste:\n",
    "    translated_text = client.translate(i, target_language='fr')\n",
    "    resultat.append(translated_text['translatedText'])\n",
    "  return resultat\n",
    "\n",
    "#fonction de tokenisation d'une liste dans une liste\n",
    "def tokenize(liste):\n",
    "  resultat = []\n",
    "  for i in liste:\n",
    "    mot_tokenize =  word_tokenize(i.lower(), language = 'french')\n",
    "    for k in mot_tokenize:\n",
    "      resultat.append(k)\n",
    "  return resultat\n",
    "\n",
    "# fonction de retrait des mots vides (A REPRENDRE AVEC SPACY???)\n",
    "def stop_word_spacy(liste):\n",
    "  stop_words = spacy.lang.fr.stop_words.STOP_WORDS\n",
    "  tokens = [i for i in liste if i not in stop_words]\n",
    "  return tokens\n",
    "\n",
    "def nettoyage(tokens):\n",
    "  stop_words = set(stopwords.words('french'))\n",
    "  result=[token for token in tokens if token not in stop_words]\n",
    "  return result\n",
    "\n",
    "#fonction de retrait des caractères non alpha-numeriques\n",
    "\n",
    "def alphanum(tokens):\n",
    "  result = [token for token in tokens if token.isalnum()]\n",
    "  return result\n",
    "\n",
    "#fonction de retrait des mots exclusivement numériques\n",
    "def retrait_chiffres(tokens):\n",
    "  result=[token for token in tokens if not (token.isnumeric ())]\n",
    "  return result\n",
    "\n",
    "def retrait_accents(liste):\n",
    "  return [unidecode(i) for i in liste]\n",
    "\n",
    "def filtre_emails_ou_sites(liste):\n",
    "    result = []\n",
    "    import re\n",
    "    for token in liste:\n",
    "      # Vérifier si le mot est une adresse e-mail\n",
    "      if re.match(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', token):\n",
    "        continue\n",
    "      # Vérifier si le mot est un site web (URL)\n",
    "      if re.match(r'\\b(?:https?://|www\\.)\\S+\\b', token):\n",
    "        continue\n",
    "      # Si ce n'est ni une adresse e-mail ni un site web, ajouter le mot à la liste filtrée\n",
    "      result.append(token)\n",
    "    return result\n",
    "\n",
    "#fonction de lemmatisation avec SPACY\n",
    "def lem_word(words):\n",
    "  lemmes = [token.lemma_ for token in nlp(\" \".join(words))]\n",
    "  return lemmes\n",
    "\n",
    "#fonction de stemming\n",
    "\n",
    "def stemming(liste):\n",
    "  result = [porter_stemmer.stem(i) for i in liste]\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bJQLiJ3YemhB"
   },
   "outputs": [],
   "source": [
    "def post_traduction(df):\n",
    "  #retrait des colonnes texte et texte découpé\n",
    "  df = df.drop(columns=['texte','texte_decoupe'])\n",
    "  #retrait des balises à une liste de liste de mots\n",
    "  df[\"mots\"] = df[\"mots\"].apply(encodage_html_liste)\n",
    "  #retokenisation\n",
    "  df[\"mots\"] = df[\"mots\"].apply(tokenize)\n",
    "  #retrait des mots vides\n",
    "  df['mots'] = df['mots'].apply(stop_word_spacy)\n",
    "  #retrait des accents\n",
    "  df['mots'] = df['mots'].apply(retrait_accents)\n",
    "  #suppression des caractères non alpha numériques\n",
    "  df[\"mots\"] = df[\"mots\"].apply(alphanum)\n",
    "  #détection et retrait adresse mail\n",
    "  df['mots'] = df['mots'].apply(filtre_emails_ou_sites)\n",
    "  #ajout de deux colonnes de stemming\n",
    "  df[\"mots_stem\"] =  df[\"mots\"].apply(stemming)\n",
    "  df[\"mots_stem_sans_chiffres\"] =  df[\"mots_stem\"].apply(retrait_chiffres)\n",
    "  #ajout de deux colonnes de lemmatisation\n",
    "  df['mots_lem'] = df['mots'].apply(lem_word)\n",
    "  df[\"mots_lem_sans_chiffres\"] =  df[\"mots_lem\"].apply(retrait_chiffres)\n",
    "  #ajout d'une colonne qui stem apres lem\n",
    "  df[\"mots_lem_stem\"] = df[\"mots_lem\"].apply(stemming)\n",
    "  df[\"mots_lem_stem_sans_chiffres\"] = df[\"mots_lem_stem\"].apply(retrait_chiffres)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7LDsQOJy95sh"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (4211843214.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_15452\\4211843214.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    df_train = load(\"C:\\Users\\franc\\AVR23_CDS_Rakuten\\notebooks\\df_train.joblib\")\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "df_train = load(\"C:\\Users\\franc\\AVR23_CDS_Rakuten\\notebooks\\df_train.joblib\")\n",
    "df_test = load('df_test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oSzsSC-ApZ4",
    "outputId": "5474d54f-0f0b-4ce9-d20e-8dd5590ef94e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-16ad8cf43481>:38: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(item, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['df_train_post_trad.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_post_trad = post_traduction(df_train)\n",
    "dump(df_train_post_trad,'df_train_post_trad.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYCZ9w8y_s5u",
    "outputId": "d645cc82-ae50-489f-9784-368658af7950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_train_post_trad.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_train_post_trad,'df_train_post_trad.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd9C5WV6_MrM"
   },
   "outputs": [],
   "source": [
    "df_train_post_trad = load('df_train_post_trad.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "ZFYgsz3ilwt3",
    "outputId": "e40b6ecf-4c72-4854-9b17-c3aee9d49c2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9d86c1c8-c6af-453a-8ba1-41a2ca1059f2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>description_vide</th>\n",
       "      <th>langue_texte</th>\n",
       "      <th>mots</th>\n",
       "      <th>mots_stem</th>\n",
       "      <th>mots_stem_sans_chiffres</th>\n",
       "      <th>mots_lem</th>\n",
       "      <th>mots_lem_sans_chiffres</th>\n",
       "      <th>mots_lem_stem</th>\n",
       "      <th>mots_lem_stem_sans_chiffres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>2280</td>\n",
       "      <td>True</td>\n",
       "      <td>fr</td>\n",
       "      <td>[journal, arts, ndeg, 133, 28, 09, 2001, l, ar...</td>\n",
       "      <td>[journal, art, ndeg, 133, 28, 09, 2001, l, art...</td>\n",
       "      <td>[journal, art, ndeg, l, art, march, salon, d, ...</td>\n",
       "      <td>[journal, art, ndeg, 133, 28, 09, 2001, l, art...</td>\n",
       "      <td>[journal, art, ndeg, l, art, marche, salon, d,...</td>\n",
       "      <td>[journal, art, ndeg, 133, 28, 09, 2001, l, art...</td>\n",
       "      <td>[journal, art, ndeg, l, art, march, salon, d, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>fr</td>\n",
       "      <td>[grand, stylet, ergonomique, bleu, gamepad, ni...</td>\n",
       "      <td>[grand, stylet, ergonom, bleu, gamepad, ninten...</td>\n",
       "      <td>[grand, stylet, ergonom, bleu, gamepad, ninten...</td>\n",
       "      <td>[grand, stylet, ergonomique, bleu, gamepad, ni...</td>\n",
       "      <td>[grand, stylet, ergonomique, bleu, gamepad, ni...</td>\n",
       "      <td>[grand, stylet, ergonom, bleu, gamepad, ninten...</td>\n",
       "      <td>[grand, stylet, ergonom, bleu, gamepad, ninten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>1280</td>\n",
       "      <td>True</td>\n",
       "      <td>fr</td>\n",
       "      <td>[peluche, donald, europe, disneyland, 2000, ma...</td>\n",
       "      <td>[peluch, donald, europ, disneyland, 2000, mari...</td>\n",
       "      <td>[peluch, donald, europ, disneyland, marionnet,...</td>\n",
       "      <td>[peluche, donald, europe, disneyland, 2000, ma...</td>\n",
       "      <td>[peluche, donald, europe, disneyland, marionne...</td>\n",
       "      <td>[peluch, donald, europ, disneyland, 2000, mari...</td>\n",
       "      <td>[peluch, donald, europ, disneyland, marionnet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>2705</td>\n",
       "      <td>False</td>\n",
       "      <td>fr</td>\n",
       "      <td>[guerre, tuques, luc, idees, grandeur, veut, o...</td>\n",
       "      <td>[guerr, tuqu, luc, ide, grandeur, veut, organi...</td>\n",
       "      <td>[guerr, tuqu, luc, ide, grandeur, veut, organi...</td>\n",
       "      <td>[guerre, tuque, luc, idees, grandeur, vouloir,...</td>\n",
       "      <td>[guerre, tuque, luc, idees, grandeur, vouloir,...</td>\n",
       "      <td>[guerr, tuqu, luc, ide, grandeur, vouloir, org...</td>\n",
       "      <td>[guerr, tuqu, luc, ide, grandeur, vouloir, org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5862738</td>\n",
       "      <td>393356830</td>\n",
       "      <td>2280</td>\n",
       "      <td>True</td>\n",
       "      <td>fr</td>\n",
       "      <td>[afrique, contemporaine, ndeg, 212, hiver, 200...</td>\n",
       "      <td>[afriqu, contemporain, ndeg, 212, hiv, 2004, d...</td>\n",
       "      <td>[afriqu, contemporain, ndeg, hiv, dossi, japon...</td>\n",
       "      <td>[afrique, contemporain, ndeg, 212, hiver, 2004...</td>\n",
       "      <td>[afrique, contemporain, ndeg, hiver, dossier, ...</td>\n",
       "      <td>[afriqu, contemporain, ndeg, 212, hiv, 2004, d...</td>\n",
       "      <td>[afriqu, contemporain, ndeg, hiv, dossi, japon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d86c1c8-c6af-453a-8ba1-41a2ca1059f2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9d86c1c8-c6af-453a-8ba1-41a2ca1059f2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9d86c1c8-c6af-453a-8ba1-41a2ca1059f2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8f85c016-29c6-4abc-ae33-f131736b9a2c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f85c016-29c6-4abc-ae33-f131736b9a2c')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8f85c016-29c6-4abc-ae33-f131736b9a2c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   productid     imageid  prdtypecode  description_vide langue_texte  \\\n",
       "1  436067568  1008141237         2280              True           fr   \n",
       "2  201115110   938777978           50             False           fr   \n",
       "3   50418756   457047496         1280              True           fr   \n",
       "4  278535884  1077757786         2705             False           fr   \n",
       "5    5862738   393356830         2280              True           fr   \n",
       "\n",
       "                                                mots  \\\n",
       "1  [journal, arts, ndeg, 133, 28, 09, 2001, l, ar...   \n",
       "2  [grand, stylet, ergonomique, bleu, gamepad, ni...   \n",
       "3  [peluche, donald, europe, disneyland, 2000, ma...   \n",
       "4  [guerre, tuques, luc, idees, grandeur, veut, o...   \n",
       "5  [afrique, contemporaine, ndeg, 212, hiver, 200...   \n",
       "\n",
       "                                           mots_stem  \\\n",
       "1  [journal, art, ndeg, 133, 28, 09, 2001, l, art...   \n",
       "2  [grand, stylet, ergonom, bleu, gamepad, ninten...   \n",
       "3  [peluch, donald, europ, disneyland, 2000, mari...   \n",
       "4  [guerr, tuqu, luc, ide, grandeur, veut, organi...   \n",
       "5  [afriqu, contemporain, ndeg, 212, hiv, 2004, d...   \n",
       "\n",
       "                             mots_stem_sans_chiffres  \\\n",
       "1  [journal, art, ndeg, l, art, march, salon, d, ...   \n",
       "2  [grand, stylet, ergonom, bleu, gamepad, ninten...   \n",
       "3  [peluch, donald, europ, disneyland, marionnet,...   \n",
       "4  [guerr, tuqu, luc, ide, grandeur, veut, organi...   \n",
       "5  [afriqu, contemporain, ndeg, hiv, dossi, japon...   \n",
       "\n",
       "                                            mots_lem  \\\n",
       "1  [journal, art, ndeg, 133, 28, 09, 2001, l, art...   \n",
       "2  [grand, stylet, ergonomique, bleu, gamepad, ni...   \n",
       "3  [peluche, donald, europe, disneyland, 2000, ma...   \n",
       "4  [guerre, tuque, luc, idees, grandeur, vouloir,...   \n",
       "5  [afrique, contemporain, ndeg, 212, hiver, 2004...   \n",
       "\n",
       "                              mots_lem_sans_chiffres  \\\n",
       "1  [journal, art, ndeg, l, art, marche, salon, d,...   \n",
       "2  [grand, stylet, ergonomique, bleu, gamepad, ni...   \n",
       "3  [peluche, donald, europe, disneyland, marionne...   \n",
       "4  [guerre, tuque, luc, idees, grandeur, vouloir,...   \n",
       "5  [afrique, contemporain, ndeg, hiver, dossier, ...   \n",
       "\n",
       "                                       mots_lem_stem  \\\n",
       "1  [journal, art, ndeg, 133, 28, 09, 2001, l, art...   \n",
       "2  [grand, stylet, ergonom, bleu, gamepad, ninten...   \n",
       "3  [peluch, donald, europ, disneyland, 2000, mari...   \n",
       "4  [guerr, tuqu, luc, ide, grandeur, vouloir, org...   \n",
       "5  [afriqu, contemporain, ndeg, 212, hiv, 2004, d...   \n",
       "\n",
       "                         mots_lem_stem_sans_chiffres  \n",
       "1  [journal, art, ndeg, l, art, march, salon, d, ...  \n",
       "2  [grand, stylet, ergonom, bleu, gamepad, ninten...  \n",
       "3  [peluch, donald, europ, disneyland, marionnet,...  \n",
       "4  [guerr, tuqu, luc, ide, grandeur, vouloir, org...  \n",
       "5  [afriqu, contemporain, ndeg, hiv, dossi, japon...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_post_trad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31RRxOJmftHo"
   },
   "outputs": [],
   "source": [
    "dump(df_train_post_trad,'df_train_post_trad.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATE86FmVSK27"
   },
   "outputs": [],
   "source": [
    "df_test_post_trad = post_traduction(df_test)\n",
    "dump(df_test_post_trad,'df_test_post_trad.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsORo4CKBGZd"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
