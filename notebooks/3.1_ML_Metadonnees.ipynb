{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d503817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des packages généraux et visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#joblib\n",
    "from joblib import dump,load\n",
    "\n",
    "# ML\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, cross_val_score,cross_val_predict,cross_validate, train_test_split\n",
    "\n",
    "#Pretraitements ML\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "#Modèles\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression, LassoCV, RidgeCV,Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Metriques\n",
    "from sklearn.metrics import classification_report,mean_squared_error\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "\n",
    "#reechantillonage\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190f1a0",
   "metadata": {},
   "source": [
    "# Chargement des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77759038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('df_REGEX_encode.joblib')\n",
    "# le regex densite n'a pas fonctionné correctement : retrait\n",
    "df = df.drop(['densite_encod_freq','densite_encod_freq_2cat','densite_encod_freq_quartiles','densite_encod_freq_2cat_variante'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604ecf3",
   "metadata": {},
   "source": [
    "# Reconstitution des df pour le test des variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dc5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_freq_encodage = ['prdtypecode','masse_encod_freq', 'surface_encod_freq', 'vitesse_encod_freq','pression_encod_freq',\n",
    "'energie_alim_encod_freq', 'energie_elec_encod_freq', 'longueur_encod_freq','volume_encod_freq','memoire_encod_freq',\n",
    "'temps_encod_freq', 'chiffres_encod_freq', 'description_vide_encod_freq', 'Nb_mots_cat_encod_freq']\n",
    "\n",
    "colonnes_frequency_encodage_2cat = ['prdtypecode','masse_encod_freq_2cat', 'surface_encod_freq_2cat', 'vitesse_encod_freq_2cat', 'pression_encod_freq_2cat',\n",
    "       'energie_alim_encod_freq_2cat', 'energie_elec_encod_freq_2cat','longueur_encod_freq_2cat', 'volume_encod_freq_2cat',\n",
    "       'memoire_encod_freq_2cat', 'temps_encod_freq_2cat','chiffres_encod_freq_2cat', 'description_vide_encod_freq',\n",
    "       'Nb_mots_cat_encod_freq']\n",
    "\n",
    "colonnes_frequency_encodage_quartiles = ['prdtypecode','masse_encod_freq_2cat', 'surface_encod_freq_quartiles', 'vitesse_encod_freq_quartiles',\n",
    "       'pression_encod_freq_quartiles', 'energie_alim_encod_freq_quartiles','energie_elec_encod_freq_quartiles', 'longueur_encod_freq_quartiles',\n",
    "       'volume_encod_freq_quartiles', 'memoire_encod_freq_quartiles','temps_encod_freq_quartiles', 'chiffres_encod_freq_quartiles',\n",
    "       'description_vide_encod_freq', 'Nb_mots_cat_encod_freq']\n",
    "\n",
    "colonnes_frequency_encodage_2cat_variante = ['prdtypecode','masse_encod_freq_2cat_variante','surface_encod_freq_2cat_variante',\n",
    " 'vitesse_encod_freq_2cat_variante', 'pression_encod_freq_2cat_variante', 'energie_alim_encod_freq_2cat_variante', 'energie_elec_encod_freq_2cat_variante',\n",
    " 'longueur_encod_freq_2cat_variante', 'volume_encod_freq_2cat_variante', 'memoire_encod_freq_2cat_variante', 'temps_encod_freq_2cat_variante',\n",
    " 'chiffres_encod_freq_2cat_variante', 'description_vide_encod_freq','Nb_mots_cat_encod_freq']\n",
    "\n",
    "\n",
    "colonnes_helmert_encodage_2cat = ['prdtypecode','masse_encod_Helmert_2cat_0','surface_encod_Helmert_2cat_0', 'vitesse_encod_Helmert_2cat_0',\n",
    " 'pression_encod_Helmert_2cat_0', 'energie_alim_encod_Helmert_2cat_0', 'masse_encod_Helmert_2cat_0', 'longueur_encod_Helmert_2cat_0',\n",
    " 'volume_encod_Helmert_2cat_0', 'memoire_encod_Helmert_2cat_0', 'temps_encod_Helmert_2cat_0', 'chiffres_encod_Helmert_2cat_0',\n",
    " 'description_vide_encod_freq', 'Nb_mots_cat_encod_freq']\n",
    "                                 \n",
    "colonnes_helmert_encodage_6cat = ['prdtypecode', 'masse_encod_Helmert_6cat_0', 'masse_encod_Helmert_6cat_1', 'masse_encod_Helmert_6cat_2',\n",
    " 'masse_encod_Helmert_6cat_3', 'masse_encod_Helmert_6cat_4', 'masse_encod_Helmert_6cat_5', 'surface_encod_Helmert_6cat_0',\n",
    " 'surface_masse_encod_Helmert_6cat_1', 'surface_encod_Helmert_6cat_2', 'surface_cat_3', 'surface_masse_encod_Helmert_6cat_4',\n",
    " 'surface_masse_encod_Helmert_6cat_5', 'vitesse_encod_Helmert_6cat_0', 'vitesse_encod_Helmert_6cat_1', 'vitesse_encod_Helmert_6cat_2',\n",
    " 'pression_encod_Helmert_6cat_0', 'pression_encod_Helmert_6cat_1', 'pression_encod_Helmert_6cat_2', 'pression_encod_Helmert_6cat_3',\n",
    " 'pression_encod_Helmert_6cat_4', 'pression_encod_Helmert_6cat_5', 'energie_alim_encod_Helmert_6cat_0', 'energie_alim_encod_Helmert_6cat_1',\n",
    " 'energie_alim_encod_Helmert_6cat_2', 'energie_alim_encod_Helmert_6cat_3', 'energie_alim_encod_Helmert_6cat_4', 'energie_alim_encod_Helmert_6cat_5',\n",
    " 'energie_encod_Helmert_6cat_0', 'energie_encod_Helmert_6cat_1', 'energie_encod_Helmert_6cat_2', 'energie_encod_Helmert_6cat_3',\n",
    " 'energie_encod_Helmert_6cat_4', 'energie_encod_Helmert_6cat_5', 'longueur_encod_Helmert_6cat_0', 'longueur_encod_Helmert_6cat_1',\n",
    " 'longueur_encod_Helmert_6cat_2', 'longueur_encod_Helmert_6cat_3', 'longueur_encod_Helmert_6cat_4', 'longueur_encod_Helmert_6cat_5',\n",
    " 'volume_encod_Helmert_6cat_0', 'volume_encod_Helmert_6cat_1', 'volume_encod_Helmert_6cat_2', 'volume_encod_Helmert_6cat_3',\n",
    " 'volume_encod_Helmert_6cat_4', 'volume_encod_Helmert_6cat_5', 'memoire_encod_Helmert_6cat_0', 'memoire_encod_Helmert_6cat_1',\n",
    " 'memoire_encod_Helmert_6cat_2', 'memoire_encod_Helmert_6cat_3', 'memoire_encod_Helmert_6cat_4', 'memoire_encod_Helmert_6cat_5',\n",
    " 'temps_encod_Helmert_6cat_0', 'temps_encod_Helmert_6cat_1', 'temps_encod_Helmert_6cat_2', 'temps_encod_Helmert_6cat_3',\n",
    " 'temps_encod_Helmert_6cat_4', 'temps_encod_Helmert_6cat_5', 'chiffres_encod_Helmert_6cat_0', 'chiffres_encod_Helmert_6cat_1',\n",
    " 'chiffres_encod_Helmert_6cat_2', 'chiffres_encod_Helmert_6cat_3', 'chiffres_encod_Helmert_6cat_4','chiffres_encod_Helmert_6cat_5',\n",
    " 'description_vide_encod_freq', 'Nb_mots_cat_encod_freq']\n",
    "\n",
    "\n",
    "#Reconstitution des df pour les varinates d'encodage\n",
    "df_freq_encod_brut = df[colonnes_freq_encodage]\n",
    "df_freq_2cat = df[colonnes_frequency_encodage_2cat]\n",
    "df_freq_quartiles = df[colonnes_frequency_encodage_quartiles]\n",
    "df_freq_2cat_variante = df[colonnes_frequency_encodage_2cat_variante]\n",
    "df_helmert_encodage_2cat = df[colonnes_helmert_encodage_2cat]\n",
    "df_helmert_encodage_6cat = df[colonnes_helmert_encodage_6cat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "794c587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_freq_encod_brut.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_freq_encod_brut,'df_freq_encod_brut.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c4e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054745fa",
   "metadata": {},
   "source": [
    "# Chargement des modèles de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bbbda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=15 , random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=23,class_weight=\"balanced\",max_iter=1000)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(random_state=23,decision_function_shape=\"ovo\")  #probleme avec ce clf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23,class_weight=\"balanced\")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state = 23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f189a",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f614805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# fonction pour récupérer le nom d'un df\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "#fonction tester différents modèles et remplir une grille de résultats\n",
    "def test_model_avec_echantillonnage(liste_modele,df,echantillonnage):\n",
    "    name = get_df_name(df)\n",
    "    df_import = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec\",\"Echantillonage\",\"Dataframe\"])\n",
    "    print(f\"création d'un dataframe_score_{name}_{echantillonnage}\")\n",
    "    score = []\n",
    "    X, y = df.drop('prdtypecode',axis=1), df['prdtypecode']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        \n",
    "    for model in liste_modele:\n",
    "        debut = time.time()\n",
    "        \n",
    "        if echantillonnage == 'SMOTE':\n",
    "            smo = SMOTE()\n",
    "            X_sm, y_sm = smo.fit_resample(X_train, y_train)\n",
    "            model.fit(np.asarray(X_sm),y_sm)\n",
    "        \n",
    "        if echantillonnage == 'RUS':\n",
    "            rus = RandomUnderSampler()\n",
    "            X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "            model.fit(np.asarray(X_rus),y_rus)\n",
    "        \n",
    "        if echantillonnage == 'ROS':\n",
    "            ros = RandomOverSampler()\n",
    "            X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "            model.fit(np.asarray(X_ros),y_ros)\n",
    "        \n",
    "        if echantillonnage == 'CENTROID':\n",
    "            cc = ClusterCentroids()\n",
    "            X_cc, y_cc = cc.fit_resample(X_train, y_train)\n",
    "            model.fit(np.asarray(X_cc),y_cc)\n",
    "            \n",
    "        if echantillonnage == 'NORMAL':\n",
    "            model.fit(np.asarray(X_train),y_train)        \n",
    "        \n",
    "        y_pred = model.predict(np.asarray(X_test))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        fin = time.time()\n",
    "        duree = fin - debut\n",
    "        model_scores = {\n",
    "            \"Model\": f\"{model}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_weighted\": f1_weighted,\n",
    "            \"F1_macro\": f1_macro,\n",
    "            \"Duree en sec\": duree,\n",
    "            \"Echantillonage\": echantillonnage,\n",
    "            \"Dataframe\" : name\n",
    "        }\n",
    "        score.append(model_scores)\n",
    "    df_score = pd.DataFrame(score)\n",
    "    df = pd.concat([df_import, df_score], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "#fonction pour tester les meilleurs modèles simples en optimisant les paramètres et remplir une grille de résultats\n",
    "def test_model_pipelines_GridCV(model,df,echantillonnage):\n",
    "    \n",
    "    df_import = pd.DataFrame(columns=[\"Model\", \"Echantillonage\", \"Dataframe\", \"Accuracy\", \"F1_weighted\", \"F1_macro\", \"Duree en sec\",\"best_params\",\"best_score\"])\n",
    "    print(\"création d'un nouveau dataframe pour les meilleurs modèles\")\n",
    "    \n",
    "    name = get_df_name(df)\n",
    "    \n",
    "    score = []\n",
    "    X, y = df.drop('prdtypecode',axis=1), df['prdtypecode']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    debut = time.time() \n",
    "    model.fit(np.asarray(X_train),y_train)\n",
    "    y_pred = model.predict(np.asarray(X_test))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    best_params = model.best_params_\n",
    "    best_score = model.best_score_\n",
    "    fin = time.time()\n",
    "    duree = fin - debut\n",
    "    model_scores = {\n",
    "            \"Model\": f\"{model}\",\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"F1_weighted\": f1_weighted,\n",
    "            \"F1_macro\": f1_macro,\n",
    "            \"best_params\": best_params,\n",
    "            \"best_score\": best_score,\n",
    "            \"Duree en sec\": duree,\n",
    "            \"Echantillonage\": echantillonnage,\n",
    "            \"Dataframe\" : name\n",
    "        }\n",
    "    score.append(model_scores)\n",
    "    df_score = pd.DataFrame(score)\n",
    "    df = pd.concat([df_import, df_score], ignore_index=True)\n",
    "    print(classification_report_imbalanced(y_test, y_pred))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c12a378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "création d'un dataframe_score_df_freq_2cat_variante_NORMAL\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m liste_modele \u001b[38;5;241m=\u001b[39m [lr,knn,dt,svc,rdf,gbc,dt]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Creaation des df score\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_score_freq_2cat_variante \u001b[38;5;241m=\u001b[39m test_model_avec_echantillonnage(liste_modele,df_freq_2cat_variante,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df_score_freq_quartiles \u001b[38;5;241m=\u001b[39m test_model_avec_echantillonnage(liste_modele, df_freq_quartiles,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m df_score_freq_2cat \u001b[38;5;241m=\u001b[39m test_model_avec_echantillonnage(liste_modele, df_freq_2cat,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m, in \u001b[0;36mtest_model_avec_echantillonnage\u001b[1;34m(liste_modele, df, echantillonnage)\u001b[0m\n\u001b[0;32m     42\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39masarray(X_cc),y_cc)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m echantillonnage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNORMAL\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39masarray(X_train),y_train)        \n\u001b[0;32m     47\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39masarray(X_test))\n\u001b[0;32m     48\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1302\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1302\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1303\u001b[0m     path_func(\n\u001b[0;32m   1304\u001b[0m         X,\n\u001b[0;32m   1305\u001b[0m         y,\n\u001b[0;32m   1306\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1307\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1308\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1309\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1310\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1311\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1312\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1313\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1314\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1315\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1316\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1317\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1318\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1319\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1320\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1321\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1322\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1323\u001b[0m     )\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1325\u001b[0m )\n\u001b[0;32m   1327\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    451\u001b[0m ]\n\u001b[1;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    453\u001b[0m     func,\n\u001b[0;32m    454\u001b[0m     w0,\n\u001b[0;32m    455\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    456\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    457\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[0;32m    458\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[0;32m    459\u001b[0m )\n\u001b[0;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    461\u001b[0m     solver,\n\u001b[0;32m    462\u001b[0m     opt_res,\n\u001b[0;32m    463\u001b[0m     max_iter,\n\u001b[0;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    465\u001b[0m )\n\u001b[0;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:279\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 279\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_loss\u001b[38;5;241m.\u001b[39mloss_gradient(\n\u001b[0;32m    280\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    281\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[0;32m    282\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    283\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    284\u001b[0m )\n\u001b[0;32m    285\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    286\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2_penalty(weights, l2_reg_strength)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\sklearn\\_loss\\loss.py:253\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    251\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss_gradient(\n\u001b[0;32m    254\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[0;32m    255\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[0;32m    256\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    257\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39mloss_out,\n\u001b[0;32m    258\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39mgradient_out,\n\u001b[0;32m    259\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    260\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "liste_modele = [lr,knn,dt,svc,rdf,gbc,dt]\n",
    "\n",
    "#Creaation des df score\n",
    "df_score_freq_2cat_variante = test_model_avec_echantillonnage(liste_modele,df_freq_2cat_variante,'NORMAL')\n",
    "df_score_freq_quartiles = test_model_avec_echantillonnage(liste_modele, df_freq_quartiles,'NORMAL')\n",
    "df_score_freq_2cat = test_model_avec_echantillonnage(liste_modele, df_freq_2cat,'NORMAL')\n",
    "df_score_freq_encod_brut = test_model_avec_echantillonnage(liste_modele,df_freq_encod_brut,'NORMAL')\n",
    "df_score_helmert_encodage_2cat = test_model_avec_echantillonnage(liste_modele, df_helmert_encodage_2cat,'NORMAL')\n",
    "df_score_helmert_encodage_6cat = test_model_avec_echantillonnage(liste_modele,df_helmert_encodage_6cat,'NORMAL')\n",
    "\n",
    "#Enregistremennt des df score\n",
    "for df_name in [\"freq_encod_brut\",\"freq_2cat\",\"freq_quartiles\",\"freq_2cat_variante\",\"helmert_encodage_2cat\",\"helmert_encodage_6cat\"]:\n",
    "    dump(f'df_score_{df_name}',f'df_score_{df_name}.joblib') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfafc75b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_score_helmert_encodage_2cat.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m df_score_freq_encod_brut \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_score_freq_encod_brut.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_score_freq_quartiles \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_score_freq_quartiles.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m df_score_helmert_encodage_2cat \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_score_helmert_encodage_2cat.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m df_score_helmert_encodage_6cat \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_score_helmert_encodage_6cat.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\conda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_score_helmert_encodage_2cat.joblib'"
     ]
    }
   ],
   "source": [
    "df_score_freq_2cat = load('df_score_freq_2cat.joblib')\n",
    "df_score_freq_2cat_variante = load('df_score_freq_2cat_variante.joblib')\n",
    "df_score_freq_encod_brut = load('df_score_freq_encod_brut.joblib')\n",
    "df_score_freq_quartiles = load('df_score_freq_quartiles.joblib')\n",
    "df_score_helmert_encodage_2cat = load('df_score_helmert_encodage_2cat.joblib')\n",
    "df_score_helmert_encodage_6cat = load('df_score_helmert_encodage_6cat.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de8de397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "      <th>Echantillonage</th>\n",
       "      <th>Dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.154857</td>\n",
       "      <td>0.102323</td>\n",
       "      <td>0.106118</td>\n",
       "      <td>30.529497</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.141639</td>\n",
       "      <td>13.698628</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.143369</td>\n",
       "      <td>0.121566</td>\n",
       "      <td>279.692352</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.208830</td>\n",
       "      <td>0.175990</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.681714</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.241741</td>\n",
       "      <td>0.194970</td>\n",
       "      <td>0.165493</td>\n",
       "      <td>99.749805</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy  F1_weighted  \\\n",
       "0  LogisticRegression(class_weight='balanced', ma...  0.154857     0.102323   \n",
       "1                             KNeighborsClassifier()  0.179725     0.163909   \n",
       "2  DecisionTreeClassifier(criterion='entropy', ma...  0.243338     0.196960   \n",
       "3  SVC(decision_function_shape='ovo', random_stat...  0.216321     0.143369   \n",
       "4  RandomForestClassifier(class_weight='balanced'...  0.208830     0.175990   \n",
       "5        GradientBoostingClassifier(random_state=23)  0.241741     0.194970   \n",
       "6  DecisionTreeClassifier(criterion='entropy', ma...  0.243338     0.196960   \n",
       "\n",
       "   F1_macro  Duree en sec Echantillonage                 Dataframe  \n",
       "0  0.106118     30.529497         NORMAL  df_helmert_encodage_2cat  \n",
       "1  0.141639     13.698628         NORMAL  df_helmert_encodage_2cat  \n",
       "2  0.165999      0.043883         NORMAL  df_helmert_encodage_2cat  \n",
       "3  0.121566    279.692352         NORMAL  df_helmert_encodage_2cat  \n",
       "4  0.154056      0.681714         NORMAL  df_helmert_encodage_2cat  \n",
       "5  0.165493     99.749805         NORMAL  df_helmert_encodage_2cat  \n",
       "6  0.165999      0.042885         NORMAL  df_helmert_encodage_2cat  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_helmert_encodage_2cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e87d1c",
   "metadata": {},
   "source": [
    "## Etude l'échantillonnage (SMOTE,ROS,RUS,CENTROID) sur les 3 meilleurs modèles selectionnés et le meilleur jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c863e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_meilleurs_modeles_simples = [dt,rdf,gbc]\n",
    "for echantillonnage in ['SMOTE','ROS','RUS','CENTROID']:\n",
    "    df_score = test_model_avec_echantillonnage(liste_meilleurs_modeles_simples,df_freq_encod_brut,echantillonnage)\n",
    "    dump(df_score,f'df_score_freq_encod_brut_{echantillonnage}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bc0e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_freq_encod_brut_SMOTE = load('df_score_freq_encod_brut_SMOTE.joblib')\n",
    "df_score_freq_encod_brut_RUS = load('df_score_freq_encod_brut_RUS.joblib')\n",
    "df_score_freq_encod_brut_ROS = load('df_score_freq_encod_brut_ROS.joblib')\n",
    "df_score_freq_encod_brut_CENTROID = load('df_score_freq_encod_brut_CENTROID.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d25e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_compile = pd.concat([df_score_freq_encod_brut_SMOTE,df_score_freq_encod_brut_RUS,df_score_freq_encod_brut_ROS,df_score_freq_encod_brut_CENTROID,df_score_freq_2cat_variante,df_score_freq_quartiles,df_score_freq_2cat,df_score_df_freq_encod_brut],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a93a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_score_compile.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dump(df_score_compile,'df_score_compile.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efc0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_compile = load('df_score_compile.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9f78390d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "      <th>Echantillonage</th>\n",
       "      <th>Dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.329485</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>0.292579</td>\n",
       "      <td>3.805380</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>10.339504</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.308916</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>0.271602</td>\n",
       "      <td>679.428619</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.266180</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.252797</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.258702</td>\n",
       "      <td>0.557509</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.288837</td>\n",
       "      <td>0.281718</td>\n",
       "      <td>0.259964</td>\n",
       "      <td>27.848157</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.318126</td>\n",
       "      <td>0.324572</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.367018</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.337797</td>\n",
       "      <td>0.292025</td>\n",
       "      <td>3.967933</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.298232</td>\n",
       "      <td>0.290278</td>\n",
       "      <td>0.264554</td>\n",
       "      <td>397.433201</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>0.141627</td>\n",
       "      <td>89.489559</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.160567</td>\n",
       "      <td>0.170523</td>\n",
       "      <td>0.166187</td>\n",
       "      <td>89.445617</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.162901</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.171164</td>\n",
       "      <td>131.117409</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.162792</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>25.753445</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.205330</td>\n",
       "      <td>0.196103</td>\n",
       "      <td>0.180660</td>\n",
       "      <td>18.958306</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.271951</td>\n",
       "      <td>0.232510</td>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.239469</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>0.157784</td>\n",
       "      <td>280.907907</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.231303</td>\n",
       "      <td>0.204452</td>\n",
       "      <td>0.190821</td>\n",
       "      <td>0.747999</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.271215</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>99.949984</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.271890</td>\n",
       "      <td>0.232442</td>\n",
       "      <td>0.204520</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>0.048964</td>\n",
       "      <td>23.182599</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.146138</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.090267</td>\n",
       "      <td>3.988335</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.186786</td>\n",
       "      <td>0.074404</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>312.520605</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.175550</td>\n",
       "      <td>0.109103</td>\n",
       "      <td>0.094163</td>\n",
       "      <td>0.543547</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.224180</td>\n",
       "      <td>0.127868</td>\n",
       "      <td>0.089418</td>\n",
       "      <td>85.271535</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.153015</td>\n",
       "      <td>0.090757</td>\n",
       "      <td>0.095757</td>\n",
       "      <td>22.949978</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.171313</td>\n",
       "      <td>0.161766</td>\n",
       "      <td>0.146846</td>\n",
       "      <td>20.067374</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.249662</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>0.043882</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.150770</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>276.310663</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.219022</td>\n",
       "      <td>0.188659</td>\n",
       "      <td>0.159931</td>\n",
       "      <td>0.689180</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.247390</td>\n",
       "      <td>0.196258</td>\n",
       "      <td>0.165622</td>\n",
       "      <td>96.761049</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.204739</td>\n",
       "      <td>0.168679</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.207049</td>\n",
       "      <td>0.172555</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>23.744078</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.303389</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>18.887074</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.347845</td>\n",
       "      <td>0.340024</td>\n",
       "      <td>0.303476</td>\n",
       "      <td>0.134640</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.205187</td>\n",
       "      <td>0.177222</td>\n",
       "      <td>300.720182</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.339064</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>0.297318</td>\n",
       "      <td>1.478047</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.329792</td>\n",
       "      <td>0.302372</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>119.559146</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.339617</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.254943</td>\n",
       "      <td>0.234344</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>40.159237</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>0.261478</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>2.169227</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.239866</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.299214</td>\n",
       "      <td>0.271298</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>454.406519</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.305416</td>\n",
       "      <td>0.309608</td>\n",
       "      <td>0.271434</td>\n",
       "      <td>2.010712</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.318003</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.259348</td>\n",
       "      <td>216.058743</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.154857</td>\n",
       "      <td>0.102323</td>\n",
       "      <td>0.106118</td>\n",
       "      <td>30.529497</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.141639</td>\n",
       "      <td>13.698628</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.143369</td>\n",
       "      <td>0.121566</td>\n",
       "      <td>279.692352</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.208830</td>\n",
       "      <td>0.175990</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.681714</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.241741</td>\n",
       "      <td>0.194970</td>\n",
       "      <td>0.165493</td>\n",
       "      <td>99.749805</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              Model  Accuracy  \\\n",
       "0     0.0            DecisionTreeClassifier(random_state=23)  0.329485   \n",
       "1     1.0  RandomForestClassifier(class_weight='balanced'...  0.343117   \n",
       "2     2.0        GradientBoostingClassifier(random_state=23)  0.308916   \n",
       "3     0.0            DecisionTreeClassifier(random_state=23)  0.266180   \n",
       "4     1.0  RandomForestClassifier(class_weight='balanced'...  0.279074   \n",
       "5     2.0        GradientBoostingClassifier(random_state=23)  0.288837   \n",
       "6     0.0            DecisionTreeClassifier(random_state=23)  0.318126   \n",
       "7     1.0  RandomForestClassifier(class_weight='balanced'...  0.331819   \n",
       "8     2.0        GradientBoostingClassifier(random_state=23)  0.298232   \n",
       "9     0.0            DecisionTreeClassifier(random_state=23)  0.132568   \n",
       "10    1.0  RandomForestClassifier(class_weight='balanced'...  0.160567   \n",
       "11    2.0        GradientBoostingClassifier(random_state=23)  0.162901   \n",
       "12    0.0  LogisticRegression(class_weight='balanced', ma...  0.199681   \n",
       "13    1.0                             KNeighborsClassifier()  0.205330   \n",
       "14    2.0            DecisionTreeClassifier(random_state=23)  0.271951   \n",
       "15    3.0  SVC(decision_function_shape='ovo', random_stat...  0.239469   \n",
       "16    4.0  RandomForestClassifier(class_weight='balanced'...  0.231303   \n",
       "17    5.0        GradientBoostingClassifier(random_state=23)  0.271215   \n",
       "18    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.271890   \n",
       "19    0.0  LogisticRegression(class_weight='balanced', ma...  0.130357   \n",
       "20    1.0                             KNeighborsClassifier()  0.146138   \n",
       "21    2.0            DecisionTreeClassifier(random_state=23)  0.224242   \n",
       "22    3.0  SVC(decision_function_shape='ovo', random_stat...  0.186786   \n",
       "23    4.0  RandomForestClassifier(class_weight='balanced'...  0.175550   \n",
       "24    5.0        GradientBoostingClassifier(random_state=23)  0.224180   \n",
       "25    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.224242   \n",
       "26    0.0  LogisticRegression(class_weight='balanced', ma...  0.153015   \n",
       "27    1.0                             KNeighborsClassifier()  0.171313   \n",
       "28    2.0            DecisionTreeClassifier(random_state=23)  0.249662   \n",
       "29    3.0  SVC(decision_function_shape='ovo', random_stat...  0.224917   \n",
       "30    4.0  RandomForestClassifier(class_weight='balanced'...  0.219022   \n",
       "31    5.0        GradientBoostingClassifier(random_state=23)  0.247390   \n",
       "32    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.249724   \n",
       "33    0.0  LogisticRegression(class_weight='balanced', ma...  0.207049   \n",
       "34    1.0                             KNeighborsClassifier()  0.303389   \n",
       "35    2.0            DecisionTreeClassifier(random_state=23)  0.347845   \n",
       "36    3.0  SVC(decision_function_shape='ovo', random_stat...  0.249724   \n",
       "37    4.0  RandomForestClassifier(class_weight='balanced'...  0.339064   \n",
       "38    5.0        GradientBoostingClassifier(random_state=23)  0.329792   \n",
       "39    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.339617   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.254943   \n",
       "1     NaN                             KNeighborsClassifier()  0.266609   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "3     NaN  SVC(decision_function_shape='ovo', random_stat...  0.299214   \n",
       "4     NaN  RandomForestClassifier(class_weight='balanced'...  0.305416   \n",
       "5     NaN        GradientBoostingClassifier(random_state=23)  0.318003   \n",
       "6     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.154857   \n",
       "1     NaN                             KNeighborsClassifier()  0.179725   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.243338   \n",
       "3     NaN  SVC(decision_function_shape='ovo', random_stat...  0.216321   \n",
       "4     NaN  RandomForestClassifier(class_weight='balanced'...  0.208830   \n",
       "5     NaN        GradientBoostingClassifier(random_state=23)  0.241741   \n",
       "6     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.243338   \n",
       "\n",
       "    F1_weighted  F1_macro  Duree en sec Echantillonage  \\\n",
       "0      0.334387  0.292579      3.805380          SMOTE   \n",
       "1      0.345530  0.304955     10.339504          SMOTE   \n",
       "2      0.301573  0.271602    679.428619          SMOTE   \n",
       "3      0.271509  0.252797      0.065824            RUS   \n",
       "4      0.280965  0.258702      0.557509            RUS   \n",
       "5      0.281718  0.259964     27.848157            RUS   \n",
       "6      0.324572  0.280913      0.367018            ROS   \n",
       "7      0.337797  0.292025      3.967933            ROS   \n",
       "8      0.290278  0.264554    397.433201            ROS   \n",
       "9      0.130284  0.141627     89.489559       CENTROID   \n",
       "10     0.170523  0.166187     89.445617       CENTROID   \n",
       "11     0.163685  0.171164    131.117409       CENTROID   \n",
       "12     0.162792  0.150358     25.753445         NORMAL   \n",
       "13     0.196103  0.180660     18.958306         NORMAL   \n",
       "14     0.232510  0.204628      0.048869         NORMAL   \n",
       "15     0.176812  0.157784    280.907907         NORMAL   \n",
       "16     0.204452  0.190821      0.747999         NORMAL   \n",
       "17     0.224046  0.197334     99.949984         NORMAL   \n",
       "18     0.232442  0.204520      0.051861         NORMAL   \n",
       "19     0.051770  0.048964     23.182599         NORMAL   \n",
       "20     0.125710  0.090267      3.988335         NORMAL   \n",
       "21     0.127918  0.089587      0.028923         NORMAL   \n",
       "22     0.074404  0.045516    312.520605         NORMAL   \n",
       "23     0.109103  0.094163      0.543547         NORMAL   \n",
       "24     0.127868  0.089418     85.271535         NORMAL   \n",
       "25     0.127918  0.089587      0.028923         NORMAL   \n",
       "26     0.090757  0.095757     22.949978         NORMAL   \n",
       "27     0.161766  0.146846     20.067374         NORMAL   \n",
       "28     0.204617  0.168516      0.043882         NORMAL   \n",
       "29     0.150770  0.127888    276.310663         NORMAL   \n",
       "30     0.188659  0.159931      0.689180         NORMAL   \n",
       "31     0.196258  0.165622     96.761049         NORMAL   \n",
       "32     0.204739  0.168679      0.043883         NORMAL   \n",
       "33     0.172555  0.160296     23.744078         NORMAL   \n",
       "34     0.301026  0.261718     18.887074         NORMAL   \n",
       "35     0.340024  0.303476      0.134640         NORMAL   \n",
       "36     0.205187  0.177222    300.720182         NORMAL   \n",
       "37     0.346972  0.297318      1.478047         NORMAL   \n",
       "38     0.302372  0.272827    119.559146         NORMAL   \n",
       "39     0.327441  0.291231      0.119680         NORMAL   \n",
       "0      0.234344  0.211914     40.159237         NORMAL   \n",
       "1      0.261478  0.237828      2.169227         NORMAL   \n",
       "2      0.305787  0.271752      0.239866         NORMAL   \n",
       "3      0.271298  0.243108    454.406519         NORMAL   \n",
       "4      0.309608  0.271434      2.010712         NORMAL   \n",
       "5      0.286219  0.259348    216.058743         NORMAL   \n",
       "6      0.305787  0.271752      0.236873         NORMAL   \n",
       "0      0.102323  0.106118     30.529497         NORMAL   \n",
       "1      0.163909  0.141639     13.698628         NORMAL   \n",
       "2      0.196960  0.165999      0.043883         NORMAL   \n",
       "3      0.143369  0.121566    279.692352         NORMAL   \n",
       "4      0.175990  0.154056      0.681714         NORMAL   \n",
       "5      0.194970  0.165493     99.749805         NORMAL   \n",
       "6      0.196960  0.165999      0.042885         NORMAL   \n",
       "\n",
       "                   Dataframe  \n",
       "0         df_freq_encod_brut  \n",
       "1         df_freq_encod_brut  \n",
       "2         df_freq_encod_brut  \n",
       "3         df_freq_encod_brut  \n",
       "4         df_freq_encod_brut  \n",
       "5         df_freq_encod_brut  \n",
       "6         df_freq_encod_brut  \n",
       "7         df_freq_encod_brut  \n",
       "8         df_freq_encod_brut  \n",
       "9         df_freq_encod_brut  \n",
       "10        df_freq_encod_brut  \n",
       "11        df_freq_encod_brut  \n",
       "12     df_freq_2cat_variante  \n",
       "13     df_freq_2cat_variante  \n",
       "14     df_freq_2cat_variante  \n",
       "15     df_freq_2cat_variante  \n",
       "16     df_freq_2cat_variante  \n",
       "17     df_freq_2cat_variante  \n",
       "18     df_freq_2cat_variante  \n",
       "19         df_freq_quartiles  \n",
       "20         df_freq_quartiles  \n",
       "21         df_freq_quartiles  \n",
       "22         df_freq_quartiles  \n",
       "23         df_freq_quartiles  \n",
       "24         df_freq_quartiles  \n",
       "25         df_freq_quartiles  \n",
       "26              df_freq_2cat  \n",
       "27              df_freq_2cat  \n",
       "28              df_freq_2cat  \n",
       "29              df_freq_2cat  \n",
       "30              df_freq_2cat  \n",
       "31              df_freq_2cat  \n",
       "32              df_freq_2cat  \n",
       "33        df_freq_encod_brut  \n",
       "34        df_freq_encod_brut  \n",
       "35        df_freq_encod_brut  \n",
       "36        df_freq_encod_brut  \n",
       "37        df_freq_encod_brut  \n",
       "38        df_freq_encod_brut  \n",
       "39        df_freq_encod_brut  \n",
       "0   df_helmert_encodage_6cat  \n",
       "1   df_helmert_encodage_6cat  \n",
       "2   df_helmert_encodage_6cat  \n",
       "3   df_helmert_encodage_6cat  \n",
       "4   df_helmert_encodage_6cat  \n",
       "5   df_helmert_encodage_6cat  \n",
       "6   df_helmert_encodage_6cat  \n",
       "0   df_helmert_encodage_2cat  \n",
       "1   df_helmert_encodage_2cat  \n",
       "2   df_helmert_encodage_2cat  \n",
       "3   df_helmert_encodage_2cat  \n",
       "4   df_helmert_encodage_2cat  \n",
       "5   df_helmert_encodage_2cat  \n",
       "6   df_helmert_encodage_2cat  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_compile.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b41fff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_compile = pd.concat([df_score_compile,df_score_helmert_encodage_6cat,df_score_helmert_encodage_2cat],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2078dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "      <th>Echantillonage</th>\n",
       "      <th>Dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.329485</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>0.292579</td>\n",
       "      <td>3.805380</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>10.339504</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.308916</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>0.271602</td>\n",
       "      <td>679.428619</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.266180</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.252797</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.258702</td>\n",
       "      <td>0.557509</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.288837</td>\n",
       "      <td>0.281718</td>\n",
       "      <td>0.259964</td>\n",
       "      <td>27.848157</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.318126</td>\n",
       "      <td>0.324572</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.367018</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.337797</td>\n",
       "      <td>0.292025</td>\n",
       "      <td>3.967933</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.298232</td>\n",
       "      <td>0.290278</td>\n",
       "      <td>0.264554</td>\n",
       "      <td>397.433201</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>0.141627</td>\n",
       "      <td>89.489559</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.160567</td>\n",
       "      <td>0.170523</td>\n",
       "      <td>0.166187</td>\n",
       "      <td>89.445617</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.162901</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.171164</td>\n",
       "      <td>131.117409</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.162792</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>25.753445</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.205330</td>\n",
       "      <td>0.196103</td>\n",
       "      <td>0.180660</td>\n",
       "      <td>18.958306</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.271951</td>\n",
       "      <td>0.232510</td>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.239469</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>0.157784</td>\n",
       "      <td>280.907907</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.231303</td>\n",
       "      <td>0.204452</td>\n",
       "      <td>0.190821</td>\n",
       "      <td>0.747999</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.271215</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>99.949984</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.271890</td>\n",
       "      <td>0.232442</td>\n",
       "      <td>0.204520</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>0.048964</td>\n",
       "      <td>23.182599</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.146138</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.090267</td>\n",
       "      <td>3.988335</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.186786</td>\n",
       "      <td>0.074404</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>312.520605</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.175550</td>\n",
       "      <td>0.109103</td>\n",
       "      <td>0.094163</td>\n",
       "      <td>0.543547</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.224180</td>\n",
       "      <td>0.127868</td>\n",
       "      <td>0.089418</td>\n",
       "      <td>85.271535</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.153015</td>\n",
       "      <td>0.090757</td>\n",
       "      <td>0.095757</td>\n",
       "      <td>22.949978</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.171313</td>\n",
       "      <td>0.161766</td>\n",
       "      <td>0.146846</td>\n",
       "      <td>20.067374</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.249662</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>0.043882</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.150770</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>276.310663</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.219022</td>\n",
       "      <td>0.188659</td>\n",
       "      <td>0.159931</td>\n",
       "      <td>0.689180</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.247390</td>\n",
       "      <td>0.196258</td>\n",
       "      <td>0.165622</td>\n",
       "      <td>96.761049</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.204739</td>\n",
       "      <td>0.168679</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.207049</td>\n",
       "      <td>0.172555</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>23.744078</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.303389</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>18.887074</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.347845</td>\n",
       "      <td>0.340024</td>\n",
       "      <td>0.303476</td>\n",
       "      <td>0.134640</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.205187</td>\n",
       "      <td>0.177222</td>\n",
       "      <td>300.720182</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.339064</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>0.297318</td>\n",
       "      <td>1.478047</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.329792</td>\n",
       "      <td>0.302372</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>119.559146</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.339617</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.254943</td>\n",
       "      <td>0.234344</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>40.159237</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>0.261478</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>2.169227</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.239866</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.299214</td>\n",
       "      <td>0.271298</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>454.406519</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.305416</td>\n",
       "      <td>0.309608</td>\n",
       "      <td>0.271434</td>\n",
       "      <td>2.010712</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.318003</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.259348</td>\n",
       "      <td>216.058743</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.154857</td>\n",
       "      <td>0.102323</td>\n",
       "      <td>0.106118</td>\n",
       "      <td>30.529497</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.141639</td>\n",
       "      <td>13.698628</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              Model  Accuracy  \\\n",
       "0     0.0            DecisionTreeClassifier(random_state=23)  0.329485   \n",
       "1     1.0  RandomForestClassifier(class_weight='balanced'...  0.343117   \n",
       "2     2.0        GradientBoostingClassifier(random_state=23)  0.308916   \n",
       "3     0.0            DecisionTreeClassifier(random_state=23)  0.266180   \n",
       "4     1.0  RandomForestClassifier(class_weight='balanced'...  0.279074   \n",
       "5     2.0        GradientBoostingClassifier(random_state=23)  0.288837   \n",
       "6     0.0            DecisionTreeClassifier(random_state=23)  0.318126   \n",
       "7     1.0  RandomForestClassifier(class_weight='balanced'...  0.331819   \n",
       "8     2.0        GradientBoostingClassifier(random_state=23)  0.298232   \n",
       "9     0.0            DecisionTreeClassifier(random_state=23)  0.132568   \n",
       "10    1.0  RandomForestClassifier(class_weight='balanced'...  0.160567   \n",
       "11    2.0        GradientBoostingClassifier(random_state=23)  0.162901   \n",
       "12    0.0  LogisticRegression(class_weight='balanced', ma...  0.199681   \n",
       "13    1.0                             KNeighborsClassifier()  0.205330   \n",
       "14    2.0            DecisionTreeClassifier(random_state=23)  0.271951   \n",
       "15    3.0  SVC(decision_function_shape='ovo', random_stat...  0.239469   \n",
       "16    4.0  RandomForestClassifier(class_weight='balanced'...  0.231303   \n",
       "17    5.0        GradientBoostingClassifier(random_state=23)  0.271215   \n",
       "18    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.271890   \n",
       "19    0.0  LogisticRegression(class_weight='balanced', ma...  0.130357   \n",
       "20    1.0                             KNeighborsClassifier()  0.146138   \n",
       "21    2.0            DecisionTreeClassifier(random_state=23)  0.224242   \n",
       "22    3.0  SVC(decision_function_shape='ovo', random_stat...  0.186786   \n",
       "23    4.0  RandomForestClassifier(class_weight='balanced'...  0.175550   \n",
       "24    5.0        GradientBoostingClassifier(random_state=23)  0.224180   \n",
       "25    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.224242   \n",
       "26    0.0  LogisticRegression(class_weight='balanced', ma...  0.153015   \n",
       "27    1.0                             KNeighborsClassifier()  0.171313   \n",
       "28    2.0            DecisionTreeClassifier(random_state=23)  0.249662   \n",
       "29    3.0  SVC(decision_function_shape='ovo', random_stat...  0.224917   \n",
       "30    4.0  RandomForestClassifier(class_weight='balanced'...  0.219022   \n",
       "31    5.0        GradientBoostingClassifier(random_state=23)  0.247390   \n",
       "32    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.249724   \n",
       "33    0.0  LogisticRegression(class_weight='balanced', ma...  0.207049   \n",
       "34    1.0                             KNeighborsClassifier()  0.303389   \n",
       "35    2.0            DecisionTreeClassifier(random_state=23)  0.347845   \n",
       "36    3.0  SVC(decision_function_shape='ovo', random_stat...  0.249724   \n",
       "37    4.0  RandomForestClassifier(class_weight='balanced'...  0.339064   \n",
       "38    5.0        GradientBoostingClassifier(random_state=23)  0.329792   \n",
       "39    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.339617   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.254943   \n",
       "1     NaN                             KNeighborsClassifier()  0.266609   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "3     NaN  SVC(decision_function_shape='ovo', random_stat...  0.299214   \n",
       "4     NaN  RandomForestClassifier(class_weight='balanced'...  0.305416   \n",
       "5     NaN        GradientBoostingClassifier(random_state=23)  0.318003   \n",
       "6     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.154857   \n",
       "1     NaN                             KNeighborsClassifier()  0.179725   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.243338   \n",
       "\n",
       "    F1_weighted  F1_macro  Duree en sec Echantillonage  \\\n",
       "0      0.334387  0.292579      3.805380          SMOTE   \n",
       "1      0.345530  0.304955     10.339504          SMOTE   \n",
       "2      0.301573  0.271602    679.428619          SMOTE   \n",
       "3      0.271509  0.252797      0.065824            RUS   \n",
       "4      0.280965  0.258702      0.557509            RUS   \n",
       "5      0.281718  0.259964     27.848157            RUS   \n",
       "6      0.324572  0.280913      0.367018            ROS   \n",
       "7      0.337797  0.292025      3.967933            ROS   \n",
       "8      0.290278  0.264554    397.433201            ROS   \n",
       "9      0.130284  0.141627     89.489559       CENTROID   \n",
       "10     0.170523  0.166187     89.445617       CENTROID   \n",
       "11     0.163685  0.171164    131.117409       CENTROID   \n",
       "12     0.162792  0.150358     25.753445         NORMAL   \n",
       "13     0.196103  0.180660     18.958306         NORMAL   \n",
       "14     0.232510  0.204628      0.048869         NORMAL   \n",
       "15     0.176812  0.157784    280.907907         NORMAL   \n",
       "16     0.204452  0.190821      0.747999         NORMAL   \n",
       "17     0.224046  0.197334     99.949984         NORMAL   \n",
       "18     0.232442  0.204520      0.051861         NORMAL   \n",
       "19     0.051770  0.048964     23.182599         NORMAL   \n",
       "20     0.125710  0.090267      3.988335         NORMAL   \n",
       "21     0.127918  0.089587      0.028923         NORMAL   \n",
       "22     0.074404  0.045516    312.520605         NORMAL   \n",
       "23     0.109103  0.094163      0.543547         NORMAL   \n",
       "24     0.127868  0.089418     85.271535         NORMAL   \n",
       "25     0.127918  0.089587      0.028923         NORMAL   \n",
       "26     0.090757  0.095757     22.949978         NORMAL   \n",
       "27     0.161766  0.146846     20.067374         NORMAL   \n",
       "28     0.204617  0.168516      0.043882         NORMAL   \n",
       "29     0.150770  0.127888    276.310663         NORMAL   \n",
       "30     0.188659  0.159931      0.689180         NORMAL   \n",
       "31     0.196258  0.165622     96.761049         NORMAL   \n",
       "32     0.204739  0.168679      0.043883         NORMAL   \n",
       "33     0.172555  0.160296     23.744078         NORMAL   \n",
       "34     0.301026  0.261718     18.887074         NORMAL   \n",
       "35     0.340024  0.303476      0.134640         NORMAL   \n",
       "36     0.205187  0.177222    300.720182         NORMAL   \n",
       "37     0.346972  0.297318      1.478047         NORMAL   \n",
       "38     0.302372  0.272827    119.559146         NORMAL   \n",
       "39     0.327441  0.291231      0.119680         NORMAL   \n",
       "0      0.234344  0.211914     40.159237         NORMAL   \n",
       "1      0.261478  0.237828      2.169227         NORMAL   \n",
       "2      0.305787  0.271752      0.239866         NORMAL   \n",
       "3      0.271298  0.243108    454.406519         NORMAL   \n",
       "4      0.309608  0.271434      2.010712         NORMAL   \n",
       "5      0.286219  0.259348    216.058743         NORMAL   \n",
       "6      0.305787  0.271752      0.236873         NORMAL   \n",
       "0      0.102323  0.106118     30.529497         NORMAL   \n",
       "1      0.163909  0.141639     13.698628         NORMAL   \n",
       "2      0.196960  0.165999      0.043883         NORMAL   \n",
       "\n",
       "                   Dataframe  \n",
       "0         df_freq_encod_brut  \n",
       "1         df_freq_encod_brut  \n",
       "2         df_freq_encod_brut  \n",
       "3         df_freq_encod_brut  \n",
       "4         df_freq_encod_brut  \n",
       "5         df_freq_encod_brut  \n",
       "6         df_freq_encod_brut  \n",
       "7         df_freq_encod_brut  \n",
       "8         df_freq_encod_brut  \n",
       "9         df_freq_encod_brut  \n",
       "10        df_freq_encod_brut  \n",
       "11        df_freq_encod_brut  \n",
       "12     df_freq_2cat_variante  \n",
       "13     df_freq_2cat_variante  \n",
       "14     df_freq_2cat_variante  \n",
       "15     df_freq_2cat_variante  \n",
       "16     df_freq_2cat_variante  \n",
       "17     df_freq_2cat_variante  \n",
       "18     df_freq_2cat_variante  \n",
       "19         df_freq_quartiles  \n",
       "20         df_freq_quartiles  \n",
       "21         df_freq_quartiles  \n",
       "22         df_freq_quartiles  \n",
       "23         df_freq_quartiles  \n",
       "24         df_freq_quartiles  \n",
       "25         df_freq_quartiles  \n",
       "26              df_freq_2cat  \n",
       "27              df_freq_2cat  \n",
       "28              df_freq_2cat  \n",
       "29              df_freq_2cat  \n",
       "30              df_freq_2cat  \n",
       "31              df_freq_2cat  \n",
       "32              df_freq_2cat  \n",
       "33        df_freq_encod_brut  \n",
       "34        df_freq_encod_brut  \n",
       "35        df_freq_encod_brut  \n",
       "36        df_freq_encod_brut  \n",
       "37        df_freq_encod_brut  \n",
       "38        df_freq_encod_brut  \n",
       "39        df_freq_encod_brut  \n",
       "0   df_helmert_encodage_6cat  \n",
       "1   df_helmert_encodage_6cat  \n",
       "2   df_helmert_encodage_6cat  \n",
       "3   df_helmert_encodage_6cat  \n",
       "4   df_helmert_encodage_6cat  \n",
       "5   df_helmert_encodage_6cat  \n",
       "6   df_helmert_encodage_6cat  \n",
       "0   df_helmert_encodage_2cat  \n",
       "1   df_helmert_encodage_2cat  \n",
       "2   df_helmert_encodage_2cat  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_compile.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727be9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53874b60",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "      <th>Echantillonage</th>\n",
       "      <th>Dataframe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.339064</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>0.297318</td>\n",
       "      <td>1.478047</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.345530</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>10.339504</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.347845</td>\n",
       "      <td>0.340024</td>\n",
       "      <td>0.303476</td>\n",
       "      <td>0.134640</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.337797</td>\n",
       "      <td>0.292025</td>\n",
       "      <td>3.967933</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.329485</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>0.292579</td>\n",
       "      <td>3.805380</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.339617</td>\n",
       "      <td>0.327441</td>\n",
       "      <td>0.291231</td>\n",
       "      <td>0.119680</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.318126</td>\n",
       "      <td>0.324572</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.367018</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.305416</td>\n",
       "      <td>0.309608</td>\n",
       "      <td>0.271434</td>\n",
       "      <td>2.010712</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.239866</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.326661</td>\n",
       "      <td>0.305787</td>\n",
       "      <td>0.271752</td>\n",
       "      <td>0.236873</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.329792</td>\n",
       "      <td>0.302372</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>119.559146</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.308916</td>\n",
       "      <td>0.301573</td>\n",
       "      <td>0.271602</td>\n",
       "      <td>679.428619</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.303389</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>18.887074</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.298232</td>\n",
       "      <td>0.290278</td>\n",
       "      <td>0.264554</td>\n",
       "      <td>397.433201</td>\n",
       "      <td>ROS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.318003</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.259348</td>\n",
       "      <td>216.058743</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.288837</td>\n",
       "      <td>0.281718</td>\n",
       "      <td>0.259964</td>\n",
       "      <td>27.848157</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.258702</td>\n",
       "      <td>0.557509</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.266180</td>\n",
       "      <td>0.271509</td>\n",
       "      <td>0.252797</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>RUS</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.299214</td>\n",
       "      <td>0.271298</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>454.406519</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>0.261478</td>\n",
       "      <td>0.237828</td>\n",
       "      <td>2.169227</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.254943</td>\n",
       "      <td>0.234344</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>40.159237</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_6cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.271951</td>\n",
       "      <td>0.232510</td>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.271890</td>\n",
       "      <td>0.232442</td>\n",
       "      <td>0.204520</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.271215</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.197334</td>\n",
       "      <td>99.949984</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.205187</td>\n",
       "      <td>0.177222</td>\n",
       "      <td>300.720182</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.249724</td>\n",
       "      <td>0.204739</td>\n",
       "      <td>0.168679</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.249662</td>\n",
       "      <td>0.204617</td>\n",
       "      <td>0.168516</td>\n",
       "      <td>0.043882</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.231303</td>\n",
       "      <td>0.204452</td>\n",
       "      <td>0.190821</td>\n",
       "      <td>0.747999</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.165999</td>\n",
       "      <td>0.042885</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.247390</td>\n",
       "      <td>0.196258</td>\n",
       "      <td>0.165622</td>\n",
       "      <td>96.761049</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.205330</td>\n",
       "      <td>0.196103</td>\n",
       "      <td>0.180660</td>\n",
       "      <td>18.958306</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.241741</td>\n",
       "      <td>0.194970</td>\n",
       "      <td>0.165493</td>\n",
       "      <td>99.749805</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.219022</td>\n",
       "      <td>0.188659</td>\n",
       "      <td>0.159931</td>\n",
       "      <td>0.689180</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.239469</td>\n",
       "      <td>0.176812</td>\n",
       "      <td>0.157784</td>\n",
       "      <td>280.907907</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.208830</td>\n",
       "      <td>0.175990</td>\n",
       "      <td>0.154056</td>\n",
       "      <td>0.681714</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.207049</td>\n",
       "      <td>0.172555</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>23.744078</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.160567</td>\n",
       "      <td>0.170523</td>\n",
       "      <td>0.166187</td>\n",
       "      <td>89.445617</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.179725</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.141639</td>\n",
       "      <td>13.698628</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.162901</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.171164</td>\n",
       "      <td>131.117409</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.199681</td>\n",
       "      <td>0.162792</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>25.753445</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat_variante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.171313</td>\n",
       "      <td>0.161766</td>\n",
       "      <td>0.146846</td>\n",
       "      <td>20.067374</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.150770</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>276.310663</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.143369</td>\n",
       "      <td>0.121566</td>\n",
       "      <td>279.692352</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.132568</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>0.141627</td>\n",
       "      <td>89.489559</td>\n",
       "      <td>CENTROID</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DecisionTreeClassifier(random_state=23)</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', ma...</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>GradientBoostingClassifier(random_state=23)</td>\n",
       "      <td>0.224180</td>\n",
       "      <td>0.127868</td>\n",
       "      <td>0.089418</td>\n",
       "      <td>85.271535</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.146138</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.090267</td>\n",
       "      <td>3.988335</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>0.175550</td>\n",
       "      <td>0.109103</td>\n",
       "      <td>0.094163</td>\n",
       "      <td>0.543547</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.154857</td>\n",
       "      <td>0.102323</td>\n",
       "      <td>0.106118</td>\n",
       "      <td>30.529497</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_helmert_encodage_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.153015</td>\n",
       "      <td>0.090757</td>\n",
       "      <td>0.095757</td>\n",
       "      <td>22.949978</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_2cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SVC(decision_function_shape='ovo', random_stat...</td>\n",
       "      <td>0.186786</td>\n",
       "      <td>0.074404</td>\n",
       "      <td>0.045516</td>\n",
       "      <td>312.520605</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', ma...</td>\n",
       "      <td>0.130357</td>\n",
       "      <td>0.051770</td>\n",
       "      <td>0.048964</td>\n",
       "      <td>23.182599</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_quartiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              Model  Accuracy  \\\n",
       "37    4.0  RandomForestClassifier(class_weight='balanced'...  0.339064   \n",
       "1     1.0  RandomForestClassifier(class_weight='balanced'...  0.343117   \n",
       "35    2.0            DecisionTreeClassifier(random_state=23)  0.347845   \n",
       "7     1.0  RandomForestClassifier(class_weight='balanced'...  0.331819   \n",
       "0     0.0            DecisionTreeClassifier(random_state=23)  0.329485   \n",
       "39    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.339617   \n",
       "6     0.0            DecisionTreeClassifier(random_state=23)  0.318126   \n",
       "4     NaN  RandomForestClassifier(class_weight='balanced'...  0.305416   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "6     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.326661   \n",
       "38    5.0        GradientBoostingClassifier(random_state=23)  0.329792   \n",
       "2     2.0        GradientBoostingClassifier(random_state=23)  0.308916   \n",
       "34    1.0                             KNeighborsClassifier()  0.303389   \n",
       "8     2.0        GradientBoostingClassifier(random_state=23)  0.298232   \n",
       "5     NaN        GradientBoostingClassifier(random_state=23)  0.318003   \n",
       "5     2.0        GradientBoostingClassifier(random_state=23)  0.288837   \n",
       "4     1.0  RandomForestClassifier(class_weight='balanced'...  0.279074   \n",
       "3     0.0            DecisionTreeClassifier(random_state=23)  0.266180   \n",
       "3     NaN  SVC(decision_function_shape='ovo', random_stat...  0.299214   \n",
       "1     NaN                             KNeighborsClassifier()  0.266609   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.254943   \n",
       "14    2.0            DecisionTreeClassifier(random_state=23)  0.271951   \n",
       "18    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.271890   \n",
       "17    5.0        GradientBoostingClassifier(random_state=23)  0.271215   \n",
       "36    3.0  SVC(decision_function_shape='ovo', random_stat...  0.249724   \n",
       "32    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.249724   \n",
       "28    2.0            DecisionTreeClassifier(random_state=23)  0.249662   \n",
       "16    4.0  RandomForestClassifier(class_weight='balanced'...  0.231303   \n",
       "2     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.243338   \n",
       "6     NaN  DecisionTreeClassifier(criterion='entropy', ma...  0.243338   \n",
       "31    5.0        GradientBoostingClassifier(random_state=23)  0.247390   \n",
       "13    1.0                             KNeighborsClassifier()  0.205330   \n",
       "5     NaN        GradientBoostingClassifier(random_state=23)  0.241741   \n",
       "30    4.0  RandomForestClassifier(class_weight='balanced'...  0.219022   \n",
       "15    3.0  SVC(decision_function_shape='ovo', random_stat...  0.239469   \n",
       "4     NaN  RandomForestClassifier(class_weight='balanced'...  0.208830   \n",
       "33    0.0  LogisticRegression(class_weight='balanced', ma...  0.207049   \n",
       "10    1.0  RandomForestClassifier(class_weight='balanced'...  0.160567   \n",
       "1     NaN                             KNeighborsClassifier()  0.179725   \n",
       "11    2.0        GradientBoostingClassifier(random_state=23)  0.162901   \n",
       "12    0.0  LogisticRegression(class_weight='balanced', ma...  0.199681   \n",
       "27    1.0                             KNeighborsClassifier()  0.171313   \n",
       "29    3.0  SVC(decision_function_shape='ovo', random_stat...  0.224917   \n",
       "3     NaN  SVC(decision_function_shape='ovo', random_stat...  0.216321   \n",
       "9     0.0            DecisionTreeClassifier(random_state=23)  0.132568   \n",
       "21    2.0            DecisionTreeClassifier(random_state=23)  0.224242   \n",
       "25    6.0  DecisionTreeClassifier(criterion='entropy', ma...  0.224242   \n",
       "24    5.0        GradientBoostingClassifier(random_state=23)  0.224180   \n",
       "20    1.0                             KNeighborsClassifier()  0.146138   \n",
       "23    4.0  RandomForestClassifier(class_weight='balanced'...  0.175550   \n",
       "0     NaN  LogisticRegression(class_weight='balanced', ma...  0.154857   \n",
       "26    0.0  LogisticRegression(class_weight='balanced', ma...  0.153015   \n",
       "22    3.0  SVC(decision_function_shape='ovo', random_stat...  0.186786   \n",
       "19    0.0  LogisticRegression(class_weight='balanced', ma...  0.130357   \n",
       "\n",
       "    F1_weighted  F1_macro  Duree en sec Echantillonage  \\\n",
       "37     0.346972  0.297318      1.478047         NORMAL   \n",
       "1      0.345530  0.304955     10.339504          SMOTE   \n",
       "35     0.340024  0.303476      0.134640         NORMAL   \n",
       "7      0.337797  0.292025      3.967933            ROS   \n",
       "0      0.334387  0.292579      3.805380          SMOTE   \n",
       "39     0.327441  0.291231      0.119680         NORMAL   \n",
       "6      0.324572  0.280913      0.367018            ROS   \n",
       "4      0.309608  0.271434      2.010712         NORMAL   \n",
       "2      0.305787  0.271752      0.239866         NORMAL   \n",
       "6      0.305787  0.271752      0.236873         NORMAL   \n",
       "38     0.302372  0.272827    119.559146         NORMAL   \n",
       "2      0.301573  0.271602    679.428619          SMOTE   \n",
       "34     0.301026  0.261718     18.887074         NORMAL   \n",
       "8      0.290278  0.264554    397.433201            ROS   \n",
       "5      0.286219  0.259348    216.058743         NORMAL   \n",
       "5      0.281718  0.259964     27.848157            RUS   \n",
       "4      0.280965  0.258702      0.557509            RUS   \n",
       "3      0.271509  0.252797      0.065824            RUS   \n",
       "3      0.271298  0.243108    454.406519         NORMAL   \n",
       "1      0.261478  0.237828      2.169227         NORMAL   \n",
       "0      0.234344  0.211914     40.159237         NORMAL   \n",
       "14     0.232510  0.204628      0.048869         NORMAL   \n",
       "18     0.232442  0.204520      0.051861         NORMAL   \n",
       "17     0.224046  0.197334     99.949984         NORMAL   \n",
       "36     0.205187  0.177222    300.720182         NORMAL   \n",
       "32     0.204739  0.168679      0.043883         NORMAL   \n",
       "28     0.204617  0.168516      0.043882         NORMAL   \n",
       "16     0.204452  0.190821      0.747999         NORMAL   \n",
       "2      0.196960  0.165999      0.043883         NORMAL   \n",
       "6      0.196960  0.165999      0.042885         NORMAL   \n",
       "31     0.196258  0.165622     96.761049         NORMAL   \n",
       "13     0.196103  0.180660     18.958306         NORMAL   \n",
       "5      0.194970  0.165493     99.749805         NORMAL   \n",
       "30     0.188659  0.159931      0.689180         NORMAL   \n",
       "15     0.176812  0.157784    280.907907         NORMAL   \n",
       "4      0.175990  0.154056      0.681714         NORMAL   \n",
       "33     0.172555  0.160296     23.744078         NORMAL   \n",
       "10     0.170523  0.166187     89.445617       CENTROID   \n",
       "1      0.163909  0.141639     13.698628         NORMAL   \n",
       "11     0.163685  0.171164    131.117409       CENTROID   \n",
       "12     0.162792  0.150358     25.753445         NORMAL   \n",
       "27     0.161766  0.146846     20.067374         NORMAL   \n",
       "29     0.150770  0.127888    276.310663         NORMAL   \n",
       "3      0.143369  0.121566    279.692352         NORMAL   \n",
       "9      0.130284  0.141627     89.489559       CENTROID   \n",
       "21     0.127918  0.089587      0.028923         NORMAL   \n",
       "25     0.127918  0.089587      0.028923         NORMAL   \n",
       "24     0.127868  0.089418     85.271535         NORMAL   \n",
       "20     0.125710  0.090267      3.988335         NORMAL   \n",
       "23     0.109103  0.094163      0.543547         NORMAL   \n",
       "0      0.102323  0.106118     30.529497         NORMAL   \n",
       "26     0.090757  0.095757     22.949978         NORMAL   \n",
       "22     0.074404  0.045516    312.520605         NORMAL   \n",
       "19     0.051770  0.048964     23.182599         NORMAL   \n",
       "\n",
       "                   Dataframe  \n",
       "37        df_freq_encod_brut  \n",
       "1         df_freq_encod_brut  \n",
       "35        df_freq_encod_brut  \n",
       "7         df_freq_encod_brut  \n",
       "0         df_freq_encod_brut  \n",
       "39        df_freq_encod_brut  \n",
       "6         df_freq_encod_brut  \n",
       "4   df_helmert_encodage_6cat  \n",
       "2   df_helmert_encodage_6cat  \n",
       "6   df_helmert_encodage_6cat  \n",
       "38        df_freq_encod_brut  \n",
       "2         df_freq_encod_brut  \n",
       "34        df_freq_encod_brut  \n",
       "8         df_freq_encod_brut  \n",
       "5   df_helmert_encodage_6cat  \n",
       "5         df_freq_encod_brut  \n",
       "4         df_freq_encod_brut  \n",
       "3         df_freq_encod_brut  \n",
       "3   df_helmert_encodage_6cat  \n",
       "1   df_helmert_encodage_6cat  \n",
       "0   df_helmert_encodage_6cat  \n",
       "14     df_freq_2cat_variante  \n",
       "18     df_freq_2cat_variante  \n",
       "17     df_freq_2cat_variante  \n",
       "36        df_freq_encod_brut  \n",
       "32              df_freq_2cat  \n",
       "28              df_freq_2cat  \n",
       "16     df_freq_2cat_variante  \n",
       "2   df_helmert_encodage_2cat  \n",
       "6   df_helmert_encodage_2cat  \n",
       "31              df_freq_2cat  \n",
       "13     df_freq_2cat_variante  \n",
       "5   df_helmert_encodage_2cat  \n",
       "30              df_freq_2cat  \n",
       "15     df_freq_2cat_variante  \n",
       "4   df_helmert_encodage_2cat  \n",
       "33        df_freq_encod_brut  \n",
       "10        df_freq_encod_brut  \n",
       "1   df_helmert_encodage_2cat  \n",
       "11        df_freq_encod_brut  \n",
       "12     df_freq_2cat_variante  \n",
       "27              df_freq_2cat  \n",
       "29              df_freq_2cat  \n",
       "3   df_helmert_encodage_2cat  \n",
       "9         df_freq_encod_brut  \n",
       "21         df_freq_quartiles  \n",
       "25         df_freq_quartiles  \n",
       "24         df_freq_quartiles  \n",
       "20         df_freq_quartiles  \n",
       "23         df_freq_quartiles  \n",
       "0   df_helmert_encodage_2cat  \n",
       "26              df_freq_2cat  \n",
       "22         df_freq_quartiles  \n",
       "19         df_freq_quartiles  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_compile.sort_values(by ='F1_weighted', axis=0,\n",
    "                              ascending=False,\n",
    "                              inplace=False,kind='quicksort',\n",
    "                              na_position='last',ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b50bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(df_score_compile,'df_score_compile.joblib')\n",
    "df_score_compile = load('df_score_compile.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf7462",
   "metadata": {},
   "source": [
    "## Optimisation des paramètres sur les trois meilleurs modèles, le meilleur jeu de donnée et le meilleur échantillonnage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas de rééchantillonage et test des modèles Random Forest, Decision tree Classifier et Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9d662e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()  # normalisation des données\n",
    "\n",
    "#RF\n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23,class_weight=\"balanced\")\n",
    "# Contruction du pipeline\n",
    "rf_pipe = Pipeline(steps= [('normalisation', sc),    # Etape 1: Normalisation \n",
    "                            ('model', rdf)])      # Etape 2: Modèle RF\n",
    "# Renseignement des paramètres à faire varier\n",
    "params = {'model__n_estimators': [10,50,100,200,400,500], 'model__max_features': ['auto', 'sqrt', 'log2'], 'model__max_depth': [4, 5, 6, 7, 8], 'model__criterion' : ['gini', 'entropy']}\n",
    "\n",
    "#GridSearch CV\n",
    "grid_rf = GridSearchCV(estimator = rf_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "\n",
    "#DT\n",
    "dtc = DecisionTreeClassifier(random_state=123,class_weight ='balanced')                           \n",
    "# Contruction du pipeline\n",
    "dt_pipe = Pipeline(steps= [('normalisation', sc),    # Etape 1: Normalisation \n",
    "                            ('model', dtc)])      # Etape 2: Modèle DT CLF\n",
    "# Renseignement des paramètres à faire varier\n",
    "depths = np.arange(1, 21)\n",
    "num_leafs = [1, 5, 10, 20, 50, 100]\n",
    "params = [{'model__max_depth':depths,\n",
    "              'model__min_samples_leaf':num_leafs}]\n",
    "\n",
    "#GridSearch CV\n",
    "grid_dt = GridSearchCV(estimator = dt_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "\n",
    "#GBC\n",
    "gbc = GradientBoostingClassifier(random_state = 23)\n",
    "rdf = RandomForestClassifier(n_jobs = -1,random_state = 23,class_weight=\"balanced\")\n",
    "# Contruction du pipeline\n",
    "gbc_pipe = Pipeline(steps= [('normalisation', sc),    # Etape 1: Normalisation \n",
    "                            ('model', gbc)])      # Etape 2: Modèle GBC\n",
    "\n",
    "# Renseignement des paramètres à faire varier\n",
    "params = {'model__random_state':[5], 'model__learning_rate':[0.05, 0.1, 0.15], \"model__min_samples_split\":[2,10,20]}\n",
    "\n",
    "#GridSearch CV\n",
    "grid_gbc = GridSearchCV(estimator = gbc_pipe, param_grid = params, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30b88aee",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "création d'un nouveau dataframe pour les meilleurs modèles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "300 fits failed out of a total of 900.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Frederic\\conda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.21837581 0.21981885 0.22351858 0.21915874 0.22333436 0.22293522\n",
      " 0.21837581 0.21981885 0.22351858 0.21915874 0.22333436 0.22293522\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.22381025 0.23692048 0.2391311  0.24200184 0.24085048 0.24078907\n",
      " 0.22381025 0.23692048 0.2391311  0.24200184 0.24085048 0.24078907\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.24427387 0.25092109 0.25385324 0.25594105 0.25641695 0.25600246\n",
      " 0.24427387 0.25092109 0.25385324 0.25594105 0.25641695 0.25600246\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.25489714 0.2653669  0.26811483 0.26616518 0.26644151 0.26644151\n",
      " 0.25489714 0.2653669  0.26811483 0.26616518 0.26644151 0.26644151\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.26705557 0.27416334 0.27493092 0.27691127 0.27715689 0.27692662\n",
      " 0.26705557 0.27416334 0.27493092 0.27691127 0.27715689 0.27692662\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.214891   0.21961928 0.21918944 0.21961928 0.22186061 0.22035616\n",
      " 0.214891   0.21961928 0.21918944 0.21961928 0.22186061 0.22035616\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.22926006 0.23632177 0.24052809 0.23920786 0.24072766 0.24043598\n",
      " 0.22926006 0.23632177 0.24052809 0.23920786 0.24072766 0.24043598\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.24101934 0.24849555 0.24915566 0.25122812 0.25156586 0.25179613\n",
      " 0.24101934 0.24849555 0.24915566 0.25122812 0.25156586 0.25179613\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.25512742 0.26357077 0.26576604 0.26613448 0.26607307 0.26661038\n",
      " 0.25512742 0.26357077 0.26576604 0.26613448 0.26607307 0.26661038\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.26751612 0.27531471 0.27663494 0.27780166 0.27906049 0.27915259\n",
      " 0.26751612 0.27531471 0.27663494 0.27780166 0.27906049 0.27915259]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         10       0.21      0.59      0.92      0.31      0.74      0.52       596\n",
      "         40       0.33      0.10      0.99      0.16      0.32      0.09       421\n",
      "         50       0.00      0.00      1.00      0.00      0.00      0.00       312\n",
      "         60       0.20      0.62      0.97      0.31      0.78      0.59       175\n",
      "       1140       0.24      0.20      0.98      0.22      0.44      0.18       463\n",
      "       1160       0.20      0.60      0.89      0.30      0.73      0.52       711\n",
      "       1180       0.00      0.00      1.00      0.00      0.00      0.00       138\n",
      "       1280       0.33      0.00      1.00      0.00      0.03      0.00       958\n",
      "       1281       0.08      0.19      0.95      0.11      0.42      0.16       394\n",
      "       1300       0.44      0.33      0.97      0.37      0.56      0.30       988\n",
      "       1301       0.09      0.07      0.99      0.07      0.25      0.06       123\n",
      "       1302       0.17      0.05      0.99      0.08      0.22      0.05       475\n",
      "       1320       0.70      0.10      1.00      0.18      0.32      0.09       636\n",
      "       1560       0.35      0.20      0.98      0.25      0.44      0.18      1008\n",
      "       1920       0.26      0.59      0.92      0.36      0.73      0.52       801\n",
      "       1940       0.15      0.79      0.95      0.25      0.87      0.74       157\n",
      "       2060       0.27      0.26      0.96      0.26      0.50      0.23       982\n",
      "       2220       0.07      0.20      0.98      0.11      0.45      0.18       152\n",
      "       2280       0.46      0.54      0.96      0.49      0.72      0.49       957\n",
      "       2403       0.33      0.02      1.00      0.04      0.14      0.02       853\n",
      "       2462       0.26      0.10      0.99      0.15      0.32      0.09       287\n",
      "       2522       0.29      0.39      0.94      0.33      0.60      0.34       972\n",
      "       2582       0.24      0.20      0.98      0.22      0.44      0.18       502\n",
      "       2583       0.73      0.24      0.99      0.36      0.49      0.22      1998\n",
      "       2585       0.36      0.09      0.99      0.14      0.30      0.08       506\n",
      "       2705       0.35      0.51      0.97      0.41      0.70      0.47       558\n",
      "       2905       0.40      0.72      0.99      0.52      0.85      0.70       163\n",
      "\n",
      "avg / total       0.36      0.28      0.97      0.25      0.47      0.25     16286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "liste_modele_GridCV = [grid_rf,grid_dt,grid_gbc]\n",
    "grid_rf_score_NORMAL = test_model_pipelines_GridCV(grid_rf,df_freq_encod_brut,'NORMAL')\n",
    "grid_dt_score_NORMAL = test_model_pipelines_GridCV(grid_dt,df_freq_encod_brut,'NORMAL')\n",
    "grid_gbc_score_NORMAL = test_model_pipelines_GridCV(grid_gbc,df_freq_encod_brut,'NORMAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59b2e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_score_NORMAL_compile = pd.concat([grid_gbc_score_NORMAL,grid_dt_score_NORMAL,grid_rf_score_NORMAL],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c02d510a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Echantillonage</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Duree en sec</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "      <td>0.337468</td>\n",
       "      <td>0.311536</td>\n",
       "      <td>0.285166</td>\n",
       "      <td>4594.943399</td>\n",
       "      <td>{'model__learning_rate': 0.15, 'model__min_sam...</td>\n",
       "      <td>0.336276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "      <td>0.315793</td>\n",
       "      <td>0.326044</td>\n",
       "      <td>0.281850</td>\n",
       "      <td>44.609771</td>\n",
       "      <td>{'model__max_depth': 20, 'model__min_samples_l...</td>\n",
       "      <td>0.305511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(cv=5,\\n             estimator=Pip...</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>df_freq_encod_brut</td>\n",
       "      <td>0.280179</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.222890</td>\n",
       "      <td>693.680043</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.279153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model Echantillonage  \\\n",
       "0  GridSearchCV(cv=5,\\n             estimator=Pip...         NORMAL   \n",
       "0  GridSearchCV(cv=5,\\n             estimator=Pip...         NORMAL   \n",
       "0  GridSearchCV(cv=5,\\n             estimator=Pip...         NORMAL   \n",
       "\n",
       "            Dataframe  Accuracy  F1_weighted  F1_macro  Duree en sec  \\\n",
       "0  df_freq_encod_brut  0.337468     0.311536  0.285166   4594.943399   \n",
       "0  df_freq_encod_brut  0.315793     0.326044  0.281850     44.609771   \n",
       "0  df_freq_encod_brut  0.280179     0.254799  0.222890    693.680043   \n",
       "\n",
       "                                         best_params  best_score  \n",
       "0  {'model__learning_rate': 0.15, 'model__min_sam...    0.336276  \n",
       "0  {'model__max_depth': 20, 'model__min_samples_l...    0.305511  \n",
       "0  {'model__criterion': 'entropy', 'model__max_de...    0.279153  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_score_NORMAL_compile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e37c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conservation du modèle Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada54fa8",
   "metadata": {},
   "source": [
    "# Visualisation des attributs les plus importants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d201c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1558373b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 20, 'model__min_samples_leaf': 1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DT\n",
    "dtc = DecisionTreeClassifier(random_state=123,class_weight ='balanced')                           \n",
    "# Contruction du pipeline\n",
    "dt_pipe = Pipeline(steps= [('normalisation', sc),    # Etape 1: Normalisation \n",
    "                            ('model', dtc)])      # Etape 2: Modèle DT CLF\n",
    "# Renseignement des paramètres à faire varier\n",
    "depths = np.arange(1, 21)\n",
    "num_leafs = [1, 5, 10, 20, 50, 100]\n",
    "params = [{'model__max_depth':depths,\n",
    "              'model__min_samples_leaf':num_leafs}]\n",
    "\n",
    "#GridSearch CV\n",
    "grid_dt = GridSearchCV(estimator = dt_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "X, y = df.drop('prdtypecode',axis=1), df['prdtypecode']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "grid_dt.fit(np.asarray(X_train),y_train)\n",
    "\n",
    "grid_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb4bbc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temps_encod_freq</th>\n",
       "      <td>0.136223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume_encod_freq</th>\n",
       "      <td>0.078772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description_vide_encod_freq</th>\n",
       "      <td>0.078718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiffres_encod_freq</th>\n",
       "      <td>0.056122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longueur_encod_freq</th>\n",
       "      <td>0.050853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energie_elec_encod_freq</th>\n",
       "      <td>0.036510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memoire_encod_freq</th>\n",
       "      <td>0.031831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prdtypecode</th>\n",
       "      <td>0.021990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Importance\n",
       "temps_encod_freq               0.136223\n",
       "volume_encod_freq              0.078772\n",
       "description_vide_encod_freq    0.078718\n",
       "chiffres_encod_freq            0.056122\n",
       "longueur_encod_freq            0.050853\n",
       "energie_elec_encod_freq        0.036510\n",
       "memoire_encod_freq             0.031831\n",
       "prdtypecode                    0.021990"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciation avec les meilleurs paramètres\n",
    "dtc = DecisionTreeClassifier(random_state=123,class_weight ='balanced',max_depth = 20, min_samples_leaf = 1)\n",
    "dtc.fit(np.asarray(X_train),y_train)\n",
    "\n",
    "#Création d'un df importance\n",
    "feats = {}\n",
    "for feature, importance in zip(df_freq_encod_brut.columns, dtc.feature_importances_):\n",
    "    feats [feature] = importance\n",
    "\n",
    "Importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})\n",
    "Importances.sort_values(by='Importance',ascending=False).head(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
