{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca5398d",
   "metadata": {},
   "source": [
    "## import et preparation des 3 df de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e346800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af375213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load(\"df_translated.joblib\")\n",
    "df.description = df.description.astype(\"str\")\n",
    "df.description_fr = df.description_fr.astype(\"str\")\n",
    "df.description_en = df.description_en.astype(\"str\")\n",
    "# fusion de désignation et description\n",
    "df[\"texte_non_traduit\"] = df.apply(lambda row: row[\"designation\"] + \" \" + row[\"description\"] if ((row[\"description\"]!='nan') and (row[\"designation\"] != row[\"description\"])) else row[\"designation\"], axis=1)\n",
    "\n",
    "df[\"texte_traduit_fr\"] = df.apply(lambda row: row[\"designation_fr\"] + \" \" + row[\"description_fr\"] if ((row[\"description_fr\"]!='nan') and (row[\"designation_fr\"] != row[\"description_fr\"])) else row[\"designation_fr\"], axis=1)\n",
    "\n",
    "df[\"texte_traduit_en\"] = df.apply(lambda row: row[\"designation_en\"] + \" \" + row[\"description_en\"] if ((row[\"description_en\"]!='nan') and (row[\"designation_en\"] != row[\"description_en\"])) else row[\"designation_en\"], axis=1)\n",
    "\n",
    "#retrait des colonnes initiales description et designation\n",
    "to_drop=['description','designation','productid', 'imageid','langues détectées', 'designation_fr', 'designation_en',\n",
    "       'description_fr', 'description_en']\n",
    "df = df.drop(columns = to_drop)\n",
    "df_texte_non_traduit = df.drop(columns =['texte_traduit_fr', 'texte_traduit_en'])\n",
    "df_texte_traduit_fr = df.drop(columns =['texte_non_traduit', 'texte_traduit_en'])\n",
    "df_texte_traduit_en = df.drop(columns =['texte_non_traduit', 'texte_traduit_fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e280e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_texte_non_traduit.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_texte_non_traduit,\"df_texte_non_traduit.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "804dfcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_texte_traduit_fr.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(df_texte_traduit_fr,\"df_texte_traduit_fr.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e500bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(df_texte_traduit_en,\"df_texte_traduit_en.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18dfd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texte_non_traduit = load(\"df_texte_non_traduit.joblib\")\n",
    "df_texte_traduit_fr = load(\"df_texte_traduit_fr.joblib\")\n",
    "df_texte_traduit_en = load(\"df_texte_traduit_en.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259118e",
   "metadata": {},
   "source": [
    "## Prepa des données FR avant DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4c99fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>texte_traduit_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Olivia : Carnet personnalisé / 150 pages / Dot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>La Guerre Des Tuques Luc a des id&amp;eacute;es de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84911</th>\n",
       "      <td>40</td>\n",
       "      <td>The Sims [ Import Anglais ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84912</th>\n",
       "      <td>2583</td>\n",
       "      <td>Kit piscine acier NEVADA déco pierre Ø 3.50m x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84913</th>\n",
       "      <td>2280</td>\n",
       "      <td>Journal Officiel De La Republique Francaise N°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84914</th>\n",
       "      <td>1560</td>\n",
       "      <td>Table Basse Bois De Récupération Massif Base B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84915</th>\n",
       "      <td>2522</td>\n",
       "      <td>Gomme De Collection 2 Gommes Pinguin Glace Ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prdtypecode                                   texte_traduit_fr\n",
       "0               10  Olivia : Carnet personnalisé / 150 pages / Dot...\n",
       "1             2280  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...\n",
       "2               50  Grand Stylet Ergonomique Bleu Gamepad Nintendo...\n",
       "3             1280  Peluche Donald - Europe - Disneyland 2000 (Mar...\n",
       "4             2705  La Guerre Des Tuques Luc a des id&eacute;es de...\n",
       "...            ...                                                ...\n",
       "84911           40                        The Sims [ Import Anglais ]\n",
       "84912         2583  Kit piscine acier NEVADA déco pierre Ø 3.50m x...\n",
       "84913         2280  Journal Officiel De La Republique Francaise N°...\n",
       "84914         1560  Table Basse Bois De Récupération Massif Base B...\n",
       "84915         2522  Gomme De Collection 2 Gommes Pinguin Glace Ver...\n",
       "\n",
       "[84916 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texte_traduit_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb28690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prdtypecode</th>\n",
       "      <th>texte_traduit_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>olivia carnet personnalise pages dot grid din ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2280</td>\n",
       "      <td>journal arts art marche salon art asiatique pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280</td>\n",
       "      <td>peluche donald europe disneyland marionnette d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2705</td>\n",
       "      <td>guerre tuques luc eacute grandeur . veut organ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prdtypecode                                   texte_traduit_fr\n",
       "0           10  olivia carnet personnalise pages dot grid din ...\n",
       "1         2280  journal arts art marche salon art asiatique pa...\n",
       "2           50  grand stylet ergonomique bleu gamepad nintendo...\n",
       "3         1280  peluche donald europe disneyland marionnette d...\n",
       "4         2705  guerre tuques luc eacute grandeur . veut organ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('french')\n",
    "\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!]+\", \" \", w)\n",
    "    w = re.sub(r'\\b\\w{0,2}\\b', '', w)\n",
    "\n",
    "    # remove stopword\n",
    "    mots = word_tokenize(w.strip())\n",
    "    mots = [mot for mot in mots if mot not in stop_words]\n",
    "    return ' '.join(mots).strip()\n",
    "\n",
    "df_texte_traduit_fr.texte_traduit_fr = df_texte_traduit_fr.texte_traduit_fr.apply(lambda x :preprocess_sentence(x))\n",
    "df_texte_traduit_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e7d01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit([  10, 2280,   50, 1280, 2705, 2522, 2582, 1560, 1281, 1920, 2403,\n",
    "       1140, 2583, 1180, 1300, 2462, 1160, 2060,   40,   60, 1320, 1302,\n",
    "       2220, 2905, 2585, 1940, 1301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce3aa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_fr = df_texte_traduit_fr.texte_traduit_fr\n",
    "\n",
    "\n",
    "target_fr = df_texte_traduit_fr.prdtypecode\n",
    "target_fr_encoded = le.transform(target_fr)\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(features_fr, target_fr_encoded, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b600970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Définition du tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "# Mettre à jour le dictionnaire du tokenizer\n",
    "tokenizer.fit_on_texts(X_text_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8c9abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dictionnaires\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24f285be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_text_train)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51228f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen, padding='post', truncating='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca6aad9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 200)         2000000   \n",
      "                                                                 \n",
      " rnn_2 (RNN)                 (None, None, 128)         126720    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " global_average_pooling1d_2  (None, 128)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2166683 (8.27 MB)\n",
      "Trainable params: 2166683 (8.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, RNN, GRUCell, Dropout\n",
    "embedding_dim = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, embedding_dim))\n",
    "model.add(RNN(GRUCell(128), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(27, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa0f0e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1062/1062 [==============================] - 1426s 1s/step - loss: 1.6919 - accuracy: 0.4919 - val_loss: 0.9530 - val_accuracy: 0.7159\n",
      "Epoch 2/10\n",
      "1062/1062 [==============================] - 1328s 1s/step - loss: 0.8218 - accuracy: 0.7549 - val_loss: 0.7917 - val_accuracy: 0.7665\n",
      "Epoch 3/10\n",
      "1062/1062 [==============================] - 2019s 2s/step - loss: 0.6323 - accuracy: 0.8101 - val_loss: 0.7578 - val_accuracy: 0.7759\n",
      "Epoch 4/10\n",
      "1062/1062 [==============================] - 1522s 1s/step - loss: 0.5169 - accuracy: 0.8416 - val_loss: 0.7622 - val_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "1062/1062 [==============================] - 1957s 2s/step - loss: 0.4345 - accuracy: 0.8641 - val_loss: 0.8098 - val_accuracy: 0.7816\n",
      "Epoch 6/10\n",
      "1062/1062 [==============================] - 1954s 2s/step - loss: 0.3695 - accuracy: 0.8824 - val_loss: 0.8671 - val_accuracy: 0.7776\n",
      "Epoch 7/10\n",
      "1062/1062 [==============================] - 2043s 2s/step - loss: 0.3143 - accuracy: 0.9004 - val_loss: 0.9525 - val_accuracy: 0.7766\n",
      "Epoch 8/10\n",
      "1062/1062 [==============================] - 2132s 2s/step - loss: 0.2685 - accuracy: 0.9143 - val_loss: 1.0284 - val_accuracy: 0.7736\n",
      "Epoch 9/10\n",
      "1062/1062 [==============================] - 2026s 2s/step - loss: 0.2335 - accuracy: 0.9237 - val_loss: 1.1352 - val_accuracy: 0.7703\n",
      "Epoch 10/10\n",
      "1062/1062 [==============================] - 2015s 2s/step - loss: 0.2079 - accuracy: 0.9327 - val_loss: 1.2239 - val_accuracy: 0.7730\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "    batch_size = 64,\n",
    "    epochs=10,\n",
    "    validation_data = [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f79b96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 59s 447ms/step - loss: 1.2239 - accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2239493131637573, 0.7729628086090088]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b9e9988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL_text\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DL_text\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"DL_text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
